{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bf55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import math\n",
    "from nltk.util import ngrams\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4839a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read dataframes\n",
    "# df1 = pd.read_pickle('testing_data_static_2022-04-10.pkl')\n",
    "# df2 = pd.read_pickle('testing_data_update_2022-04-10_2023-04-10.pkl')\n",
    "# df3 = pd.read_pickle('testing_data_with_duplicates.pkl')\n",
    "\n",
    "# # Concatenate dataframes\n",
    "# testing_data = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# # Remove rows with duplicate data in the 'raw' column\n",
    "# testing_data = testing_data.drop_duplicates(subset='raw')\n",
    "\n",
    "# # Reset index after dropping duplicates\n",
    "# testing_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sm_df = pd.read_pickle('updated_testing_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8778dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis (VADER)\n",
    "# authoredAt column datetime manipulation for timeseries grouping\n",
    "sm_df['authoredAt'] = pd.to_datetime(sm_df['authoredAt'])\n",
    "sm_df['authoredAt'] = sm_df['authoredAt'].dt.date.astype('datetime64[ns]')\n",
    "sm_df['weekAuthored'] = sm_df['authoredAt'].dt.isocalendar().week\n",
    "\n",
    "platform_list = sm_df['platform'].unique()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sm_df['negative'] = None\n",
    "sm_df['positive'] = None\n",
    "sm_df['compound'] = None\n",
    "sm_df['sentiment'] = None\n",
    "\n",
    "# print(sm_df.head(10))\n",
    "\n",
    "index = len(sm_df) - 1\n",
    "while index >= 0:\n",
    "    timeNotValid = False\n",
    "    sentimentNotValid = False\n",
    "    \n",
    "    if pd.isnull(sm_df.at[index, 'weekAuthored']) or not isinstance(sm_df.at[index, 'authoredAt'], pd.Timestamp):\n",
    "        # Check if 'weekAuthored' is null or 'authoredAt' is not of datetime type\n",
    "        # If any of the conditions are true, update the values\n",
    "        sm_df.at[index, 'authoredAt'] = pd.to_datetime(sm_df.at[index, 'authoredAt'], errors='coerce')\n",
    "        sm_df.at[index, 'authoredAt'] = sm_df.at[index, 'authoredAt'].date().astype('datetime64[ns]')\n",
    "        timeNotValid = True\n",
    "    \n",
    "    if (sm_df.at[index, 'negative'] is None) or (sm_df.at[index, 'positive'] is None) \\\n",
    "       or (sm_df.at[index, 'neutral'] is None) or (sm_df.at[index, 'compound'] is None):\n",
    "        text = sm_df.at[index, 'content']\n",
    "        sm_df.at[index, 'sentiment'] = analyzer.polarity_scores(text)\n",
    "        sm_df.at[index, 'negative'] = sm_df.at[index, 'sentiment']['neg']\n",
    "        sm_df.at[index, 'positive'] = sm_df.at[index, 'sentiment']['pos']\n",
    "        sm_df.at[index, 'neutral'] = sm_df.at[index, 'sentiment']['neu']\n",
    "        sm_df.at[index, 'compound'] = sm_df.at[index, 'sentiment']['compound']\n",
    "        sentimentNotValid = True\n",
    "\n",
    "    if not timeNotValid and not sentimentNotValid:\n",
    "        break\n",
    "        \n",
    "    index -= 1\n",
    "    \n",
    "# One-Hot Encoding Account Labels\n",
    "unique_values = set(val for sublist in sm_df['labels'] for val in sublist)\n",
    "# print(unique_values)\n",
    "for value in unique_values:\n",
    "    sm_df[value] = sm_df['labels'].apply(lambda x: 1 if value in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f61f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller function to generate TF-IDF Matrix\n",
    "def generate_matrix(sentences, documents):\n",
    "    sentences = nltk.sent_tokenize(text) # NLTK function\n",
    "    total_documents = documents\n",
    "\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    documents_per_words = _create_documents_per_words(freq_matrix)\n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, documents_per_words, total_documents)\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    \n",
    "    return tf_idf_matrix\n",
    "\n",
    "# Create word frequency matrix for documents\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    ps = SnowballStemmer(\"english\")\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        dictionary_tokenizer = MWETokenizer(words, separator=' ') \n",
    "        dictionary_based_token = dictionary_tokenizer.tokenize(words) \n",
    "\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "                \n",
    "        # Adding bigrams as phrases\n",
    "        bigrams = list(nltk.bigrams(words))\n",
    "        for bigram in bigrams:\n",
    "            phrase = ' '.join(bigram)\n",
    "            phrase_words = phrase.split(' ')\n",
    "            if all(word not in stopWords for word in phrase_words):\n",
    "                if phrase in freq_table:\n",
    "                    freq_table[phrase] += 1\n",
    "                else:\n",
    "                    freq_table[phrase] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "# Create TF (text frequency) matrix for documents\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "# Find number of documents per words\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "# Create IDF (inverse document frequency) matrix for documents\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            if float(count_doc_per_words[word]) == 0 or total_documents == 0:\n",
    "                idf_table[word] = 0.0\n",
    "            else:\n",
    "                idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "# TF-IDF = TF * IDF matrices\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c896f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = {\n",
    "    \"'ll\", \"'tis\", \"'twas\", \"'ve\", \"10\", \"39\", \"a\", \"a's\", \"able\", \"ableabout\", \"about\", \"above\", \"abroad\",\n",
    "    \"abst\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\",\n",
    "    \"adopted\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\",\n",
    "    \"ago\", \"ah\", \"ahead\", \"ai\", \"ain't\", \"aint\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\",\n",
    "    \"alongside\", \"already\", \"also\", \"although\", \"always\", \"am\", \"amid\", \"amidst\", \"among\", \"amongst\", \"amoungst\",\n",
    "    \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\",\n",
    "    \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\",\n",
    "    \"approximately\", \"aq\", \"ar\", \"are\", \"area\", \"areas\", \"aren\", \"aren't\", \"arent\", \"arise\", \"around\", \"arpa\",\n",
    "    \"as\", \"aside\", \"ask\", \"asked\", \"asking\", \"asks\", \"associated\", \"at\", \"au\", \"auth\", \"available\", \"aw\", \"away\",\n",
    "    \"awfully\", \"az\", \"b\", \"ba\", \"back\", \"backed\", \"backing\", \"backs\", \"backward\", \"backwards\", \"bb\", \"bd\", \"be\",\n",
    "    \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"began\", \"begin\",\n",
    "    \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"beings\", \"believe\", \"below\", \"beside\", \"besides\",\n",
    "    \"best\", \"better\", \"between\", \"beyond\", \"bf\", \"bg\", \"bh\", \"bi\", \"big\", \"bill\", \"billion\", \"biol\", \"bj\", \"bm\",\n",
    "    \"bn\", \"bo\", \"both\", \"bottom\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"but\", \"buy\", \"bv\", \"bw\", \"by\", \"bz\",\n",
    "    \"c\", \"c'mon\", \"c's\", \"ca\", \"call\", \"came\", \"can\", \"can't\", \"cannot\", \"cant\", \"caption\", \"case\", \"cases\",\n",
    "    \"cause\", \"causes\", \"cc\", \"cd\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"ck\", \"cl\", \"clear\",\n",
    "    \"clearly\", \"click\", \"cm\", \"cmon\", \"cn\", \"co\", \"co.\", \"com\", \"come\", \"comes\", \"computer\", \"con\", \"concerning\",\n",
    "    \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"copy\", \"corresponding\",\n",
    "    \"could\", \"could've\", \"couldn\", \"couldn't\", \"couldnt\", \"course\", \"cr\", \"cry\", \"cs\", \"cu\", \"currently\", \"cv\",\n",
    "    \"cx\", \"cy\", \"cz\", \"d\", \"dare\", \"daren't\", \"darent\", \"date\", \"de\", \"dear\", \"definitely\", \"describe\", \"described\",\n",
    "    \"despite\", \"detail\", \"did\", \"didn\", \"didn't\", \"didnt\", \"differ\", \"different\", \"differently\", \"directly\", \"dj\",\n",
    "    \"dk\", \"dm\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doesnt\", \"doing\", \"don\", \"don't\", \"done\", \"dont\", \"doubtful\",\n",
    "    \"down\", \"downed\", \"downing\", \"downs\", \"downwards\", \"due\", \"during\", \"dz\", \"e\", \"each\", \"early\", \"ec\", \"ed\",\n",
    "    \"edu\", \"ee\", \"effect\", \"eg\", \"eh\", \"eight\", \"eighty\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"end\",\n",
    "    \"ended\", \"ending\", \"ends\", \"enough\", \"entirely\", \"er\", \"es\", \"especially\", \"et\", \"et-al\", \"etc\", \"even\",\n",
    "    \"evenly\", \"ever\", \"evermore\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\",\n",
    "    \"example\", \"except\", \"f\", \"face\", \"faces\", \"fact\", \"facts\", \"fairly\", \"far\", \"farther\", \"felt\", \"few\", \"fewer\",\n",
    "    \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fifty\", \"fify\", \"fill\", \"find\", \"finds\", \"fire\", \"first\", \"five\", \"fix\", \"fj\",\n",
    "    \"fk\", \"fm\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"forever\", \"former\", \"formerly\", \"forth\", \"forty\",\n",
    "    \"forward\", \"found\", \"four\", \"fr\", \"free\", \"from\", \"front\", \"full\", \"fully\", \"further\", \"furthered\",\n",
    "    \"furthering\", \"furthermore\", \"furthers\", \"fx\", \"g\", \"ga\", \"gave\", \"gb\", \"gd\", \"ge\", \"general\", \"generally\",\n",
    "    \"get\", \"gets\", \"getting\", \"gf\", \"gg\", \"gh\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gl\", \"gm\", \"gmt\", \"gn\",\n",
    "    \"go\", \"goes\", \"going\", \"gone\", \"good\", \"goods\", \"got\", \"gotten\", \"gov\", \"gp\", \"gq\", \"gr\", \"great\", \"greater\",\n",
    "    \"greatest\", \"greetings\", \"group\", \"grouped\", \"grouping\", \"groups\", \"gs\", \"gt\", \"gu\", \"gw\", \"gy\", \"h\", \"had\",\n",
    "    \"hadn\", \"hadn't\", \"hadnt\", \"half\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasn't\", \"hasnt\", \"have\", \"haven\",\n",
    "    \"haven't\", \"havent\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"hed\", \"hell\", \"hello\", \"help\",     \"hence\", \"her\", \"here\", \"here's\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hers\", \"herself\",\n",
    "    \"herse\", \"hes\", \"hi\", \"hid\", \"high\", \"higher\", \"highest\", \"him\", \"himself\", \"himse\", \"his\", \"hither\", \"hk\",\n",
    "    \"hm\", \"hn\", \"home\", \"homepage\", \"hopefully\", \"how\", \"how'd\", \"how'll\", \"how's\", \"howbeit\", \"however\", \"hr\",\n",
    "    \"ht\", \"htm\", \"html\", \"http\", \"hu\", \"hundred\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"i.e.\", \"id\", \"ie\", \"if\",\n",
    "    \"ignored\", \"ii\", \"il\", \"ill\", \"im\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\",\n",
    "    \"inc\", \"inc.\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"inside\",\n",
    "    \"insofar\", \"instead\", \"int\", \"interest\", \"interested\", \"interesting\", \"interests\", \"into\", \"invention\",\n",
    "    \"inward\", \"io\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"isnt\", \"it\", \"it'd\", \"it'll\", \"it's\", \"itd\", \"itll\",\n",
    "    \"its\", \"itself\", \"itse\", \"ive\", \"j\", \"je\", \"jm\", \"jo\", \"join\", \"jp\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\",\n",
    "    \"kept\", \"keys\", \"kg\", \"kh\", \"ki\", \"kind\", \"km\", \"kn\", \"knew\", \"know\", \"known\", \"knows\", \"kp\", \"kr\", \"kw\",\n",
    "    \"ky\", \"kz\", \"l\", \"la\", \"large\", \"largely\", \"last\", \"lately\", \"later\", \"latest\", \"latter\", \"latterly\", \"lb\",\n",
    "    \"lc\", \"least\", \"length\", \"less\", \"lest\", \"let\", \"let's\", \"lets\", \"li\", \"like\", \"liked\", \"likely\", \"likewise\",\n",
    "    \"line\", \"little\", \"lk\", \"ll\", \"long\", \"longer\", \"longest\", \"look\", \"looking\", \"looks\", \"low\", \"lower\", \"lr\",\n",
    "    \"ls\", \"lt\", \"ltd\", \"lu\", \"lv\", \"ly\", \"m\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"making\", \"man\", \"many\",\n",
    "    \"may\", \"maybe\", \"mayn't\", \"maynt\", \"mc\", \"md\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"member\",\n",
    "    \"members\", \"men\", \"merely\", \"mg\", \"mh\", \"microsoft\", \"might\", \"might've\", \"mightn\", \"mightn't\", \"mightnt\",\n",
    "    \"mil\", \"mill\", \"million\", \"mine\", \"minus\", \"miss\", \"mk\", \"ml\", \"mm\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\",\n",
    "    \"mostly\", \"move\", \"mp\", \"mq\", \"mr\", \"mrs\", \"ms\", \"msie\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"must've\",\n",
    "    \"mustn\", \"mustn't\", \"mustnt\", \"mv\", \"mw\", \"mx\", \"my\", \"myself\", \"myse\", \"mz\", \"n\", \"na\", \"name\", \"namely\",\n",
    "    \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needed\", \"needing\",\n",
    "    \"needn't\", \"neednt\", \"needs\", \"neither\", \"net\", \"netscape\", \"never\", \"neverf\", \"neverless\", \"nevertheless\",\n",
    "    \"new\", \"newer\", \"newest\", \"next\", \"nf\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nl\", \"no\", \"no-one\", \"nobody\", \"non\",\n",
    "    \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"notwithstanding\",\n",
    "    \"novel\", \"now\", \"nowhere\", \"np\", \"nr\", \"nu\", \"null\", \"number\", \"numbers\", \"nz\", \"o\", \"obtain\", \"obtained\",\n",
    "    \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"older\", \"oldest\", \"om\", \"omitted\", \"on\", \"once\",\n",
    "    \"one\", \"one's\", \"ones\", \"only\", \"onto\", \"open\", \"opened\", \"opening\", \"opens\", \"opposite\", \"or\", \"ord\", \"order\",\n",
    "    \"ordered\", \"ordering\", \"orders\", \"org\", \"other\", \"others\", \"otherwise\", \"ought\", \"oughtn't\", \"oughtnt\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"owing\", \"own\", \"p\", \"pa\", \"page\", \"pages\", \"part\",\n",
    "    \"parted\", \"particular\", \"particularly\", \"parting\", \"parts\", \"past\", \"pe\", \"per\", \"perhaps\", \"pf\", \"pg\", \"ph\",\n",
    "    \"pk\", \"pl\", \"place\", \"placed\", \"places\", \"please\", \"plus\", \"pm\", \"pmid\", \"pn\", \"point\", \"pointed\", \"pointing\",\n",
    "    \"points\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pr\", \"predominantly\", \"present\",\n",
    "    \"presented\", \"presenting\", \"presents\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"problem\",\n",
    "    \"problems\", \"promptly\", \"proud\", \"provided\", \"provides\", \"pt\", \"put\", \"puts\", \"pw\", \"py\", \"q\", \"qa\", \"que\",\n",
    "    \"quickly\", \"quite\", \"qv\", \"r\", \"ran\", \"rather\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\",\n",
    "    \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"reserved\",\n",
    "    \"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"ring\", \"ro\", \"room\", \"rooms\", \"round\", \"ru\",\n",
    "    \"run\", \"s\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sb\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\",\n",
    "    \"seconds\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"sees\", \"self\", \"selves\",\n",
    "    \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"seventy\", \"several\", \"sg\", \"sh\", \"shall\", \"shan't\",\n",
    "    \"shant\", \"she\", \"she'd\", \"she'll\", \"she's\", \"shed\", \"shell\", \"shes\", \"should\", \"should've\", \"shouldn\",\n",
    "    \"shouldn't\", \"shouldnt\", \"show\", \"showed\", \"showing\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"sides\",\n",
    "    \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"site\", \"six\", \"sixty\", \"sj\",\n",
    "    \"sk\", \"sl\", \"slightly\", \"sm\", \"small\", \"smaller\", \"smallest\", \"sn\", \"so\", \"some\", \"somebody\", \"someday\",\n",
    "    \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\",\n",
    "    \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sr\", \"st\", \"state\", \"states\", \"still\", \"stop\",\n",
    "    \"strongly\", \"su\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\",\n",
    "    \"sv\", \"sy\", \"system\", \"sz\", \"t\", \"t's\", \"take\", \"taken\", \"taking\", \"tc\", \"td\", \"tell\", \"ten\", \"tends\", \"test\",\n",
    "    \"text\", \"tf\", \"tg\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"that's\", \"that've\", \"thatll\",\n",
    "    \"thats\", \"thatve\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"there'd\",\n",
    "    \"there'll\", \"there're\", \"there's\", \"there've\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\",\n",
    "    \"therell\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"thereve\", \"these\", \"they\", \"they'd\",\n",
    "    \"they'll\", \"they're\", \"they've\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"thick\", \"thin\", \"thing\", \"things\",\n",
    "    \"think\", \"thinks\", \"third\", \"thirty\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\",\n",
    "    \"thought\", \"thoughts\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"til\", \"till\",\n",
    "    \"tip\", \"tis\", \"tj\", \"tk\", \"tm\", \"tn\", \"to\", \"today\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\",\n",
    "    \"tp\", \"tr\", \"tried\", \"tries\", \"trillion\", \"truly\", \"try\", \"trying\", \"ts\", \"tt\", \"turn\", \"turned\", \"turning\",\n",
    "    \"turns\", \"tv\", \"tw\", \"twas\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tz\", \"u\", \"ua\", \"ug\", \"uk\", \"um\", \"un\",\n",
    "    \"under\", \"underneath\", \"undoing\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"up\",\n",
    "    \"upon\", \"ups\", \"upwards\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\",\n",
    "    \"uucp\", \"uy\", \"uz\", \"v\", \"va\", \"value\", \"various\", \"vc\", \"ve\", \"versus\", \"very\", \"vg\", \"vi\", \"via\", \"viz\",\n",
    "    \"vn\", \"vol\", \"vols\", \"vs\", \"vu\", \"w\", \"want\", \"wanted\", \"wanting\", \"wants\", \"was\", \"wasn\", \"wasn't\", \"wasnt\",\n",
    "    \"way\", \"ways\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"web\", \"webpage\", \"website\", \"wed\", \"welcome\", \"well\",\n",
    "    \"wells\", \"went\", \"were\", \"weren\", \"weren't\", \"werent\", \"weve\", \"wf\", \"what\", \"what'd\", \"what'll\", \"what's\",\n",
    "    \"what've\", \"whatever\", \"whatll\", \"whats\", \"whatve\", \"when\", \"when'd\", \"when'll\", \"when's\", \"whence\",\n",
    "    \"whenever\", \"where\", \"where'd\", \"where'll\", \"where's\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\",\n",
    "    \"whereupon\", \"wherever\", \"whether\", \"which\", \"whichever\", \"while\", \"whilst\", \"whim\", \"whither\", \"who\",\n",
    "    \"who'd\", \"who'll\", \"who's\", \"whod\", \"whoever\", \"whole\", \"wholl\", \"whom\", \"whomever\", \"whos\", \"whose\", \"why\",\n",
    "    \"why'd\", \"why'll\", \"why's\", \"widely\", \"width\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"won\",\n",
    "    \"won't\", \"wonder\", \"wont\", \"words\", \"work\", \"worked\", \"working\", \"works\", \"world\", \"would\", \"would've\",\n",
    "    \"wouldn\", \"wouldn't\", \"wouldnt\", \"ws\", \"www\", \"x\", \"y\", \"ye\", \"year\", \"years\", \"yes\", \"yet\", \"you\", \"you'd\",\n",
    "    \"you'll\", \"you're\", \"you've\", \"youd\", \"youll\", \"young\", \"younger\", \"youngest\", \"your\", \"youre\", \"yours\",\n",
    "    \"yourself\", \"yourselves\", \"youve\", \"yt\", \"yu\", \"z\", \"za\", \"zero\", \"zm\", \"zr\",\n",
    "    'covid', 'coronavirus', 'corona', 'rona', 'covid-19', 'tested','testing','test','tests',\n",
    "    'symptoms','positive','negative','para','vaccine','vaccines','vaccinated','vaxxed','virus''tests',\n",
    "    'people','health','pandemic','virus','sars-cov-2','doctor','covid19','vaccination','vaccinations','rt @',\n",
    "    '-- --','',\"I'm\", r'\\u', '&', 'amp','https', 'nan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d95112",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_df['actualText'] = ''\n",
    "\n",
    "for index, row in sm_df.iterrows():\n",
    "    if (row['actualText'] == ''):\n",
    "        if (row['text_translated']) != None:\n",
    "            sm_df.at[index, 'actualText'] = str(row['text_translated'])\n",
    "        else:\n",
    "            sm_df.at[index, 'actualText'] = str(row['content'])\n",
    "\n",
    "# Use weekly-text dataframe to generate TF-IDF matrices\n",
    "weekly_text = sm_df.groupby([pd.Grouper(key='authoredAt', freq='W')])['actualText'].agg(\n",
    "    text_combined=' '.join,  # Aggregating text as before\n",
    "    count='count'  # Adding count aggregation for number of posts\n",
    ").reset_index()\n",
    "\n",
    "weekly_text = weekly_text.rename(columns={'authoredAt': 'weekAuthored'})\n",
    "weekly_text = weekly_text.rename(columns={'text_combined': 'textProcessed'})\n",
    "\n",
    "weekly_text['tfIdfMatrix'] = [{} for _ in range(len(weekly_text))]\n",
    "\n",
    "text = weekly_text.at[0, 'textProcessed']\n",
    "count = weekly_text.at[0,'count']\n",
    "\n",
    "for index, row in weekly_text[::-1].iterrows():\n",
    "    text = weekly_text.at[index, 'textProcessed']\n",
    "    count = weekly_text.at[index,'count']\n",
    "    \n",
    "    if row['tfIdfMatrix'] == {}:\n",
    "        matrix = generate_matrix(text, count)\n",
    "        # print(matrix)\n",
    "        \n",
    "        for dictionary in matrix.values():\n",
    "            weekly_text.at[index, 'tfIdfMatrix'] = dictionary\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee64378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekAuthored</th>\n",
       "      <th>textProcessed</th>\n",
       "      <th>count</th>\n",
       "      <th>tfIdfMatrix</th>\n",
       "      <th>symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>this week's review of the covid-19 pandemic in...</td>\n",
       "      <td>39</td>\n",
       "      <td>{'week': 0.010084212298055277, ''s': 0.0134456...</td>\n",
       "      <td>{decreased_sense_of_smell, fever, sore_throat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>officially part of team canada i didn't realiz...</td>\n",
       "      <td>247</td>\n",
       "      <td>{'attend': 0.0025816384077358536, 'music': 0.0...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>hi everyone i just want to share something i w...</td>\n",
       "      <td>210</td>\n",
       "      <td>{'gleyber': 0.009225490200071285, 'torres': 0....</td>\n",
       "      <td>{decreased_sense_of_taste, confusion, depressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>5 months later and saw a grand baby graduation...</td>\n",
       "      <td>222</td>\n",
       "      <td>{'emory': 0.021803662289033455, 'university': ...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>student speaks on the ingraham angle on how sh...</td>\n",
       "      <td>212</td>\n",
       "      <td>{'#': 0.041151703948002334, 'staysafe': 0.0030...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>a new study warns that men with lower testoste...</td>\n",
       "      <td>213</td>\n",
       "      <td>{'@': 0.0839901855207587, 'kff': 0.00266710149...</td>\n",
       "      <td>{decreased_sense_of_taste, stroke_heart_attack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>i had the virus back in december 2019 i did no...</td>\n",
       "      <td>199</td>\n",
       "      <td>{'#': 0.06802288537076036, 'fortheloveofdata':...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>for decades fda guidelines have limited gay an...</td>\n",
       "      <td>246</td>\n",
       "      <td>{'self-registration': 0.004111668283926706, 'p...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>has this been happening to anyone i had covid ...</td>\n",
       "      <td>205</td>\n",
       "      <td>{'info': 0.008339970096233131, ',': 0.00407137...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>healthcare providers and pharmacies continue t...</td>\n",
       "      <td>209</td>\n",
       "      <td>{'learn': 0.007383854919684327, '#': 0.0599558...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekAuthored                                      textProcessed  count  \\\n",
       "0   2021-05-02  this week's review of the covid-19 pandemic in...     39   \n",
       "1   2021-05-09  officially part of team canada i didn't realiz...    247   \n",
       "2   2021-05-16  hi everyone i just want to share something i w...    210   \n",
       "3   2021-05-23  5 months later and saw a grand baby graduation...    222   \n",
       "4   2021-05-30  student speaks on the ingraham angle on how sh...    212   \n",
       "5   2021-06-06  a new study warns that men with lower testoste...    213   \n",
       "6   2021-06-13  i had the virus back in december 2019 i did no...    199   \n",
       "7   2021-06-20  for decades fda guidelines have limited gay an...    246   \n",
       "8   2021-06-27  has this been happening to anyone i had covid ...    205   \n",
       "9   2021-07-04  healthcare providers and pharmacies continue t...    209   \n",
       "\n",
       "                                         tfIdfMatrix  \\\n",
       "0  {'week': 0.010084212298055277, ''s': 0.0134456...   \n",
       "1  {'attend': 0.0025816384077358536, 'music': 0.0...   \n",
       "2  {'gleyber': 0.009225490200071285, 'torres': 0....   \n",
       "3  {'emory': 0.021803662289033455, 'university': ...   \n",
       "4  {'#': 0.041151703948002334, 'staysafe': 0.0030...   \n",
       "5  {'@': 0.0839901855207587, 'kff': 0.00266710149...   \n",
       "6  {'#': 0.06802288537076036, 'fortheloveofdata':...   \n",
       "7  {'self-registration': 0.004111668283926706, 'p...   \n",
       "8  {'info': 0.008339970096233131, ',': 0.00407137...   \n",
       "9  {'learn': 0.007383854919684327, '#': 0.0599558...   \n",
       "\n",
       "                                            symptoms  \n",
       "0  {decreased_sense_of_smell, fever, sore_throat,...  \n",
       "1  {decreased_sense_of_taste, rash, confusion, st...  \n",
       "2  {decreased_sense_of_taste, confusion, depressi...  \n",
       "3  {decreased_sense_of_taste, rash, stroke_heart_...  \n",
       "4  {decreased_sense_of_taste, rash, stroke_heart_...  \n",
       "5  {decreased_sense_of_taste, stroke_heart_attack...  \n",
       "6  {decreased_sense_of_taste, rash, confusion, st...  \n",
       "7  {decreased_sense_of_taste, rash, stroke_heart_...  \n",
       "8  {decreased_sense_of_taste, rash, confusion, st...  \n",
       "9  {decreased_sense_of_taste, rash, stroke_heart_...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define patterns for COVID-19 symptoms\n",
    "covid_symptoms = [\n",
    "    [{\"LOWER\": {\"IN\": [\"fever\", \"high temperature\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"headache\", \"migraine\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"cough\", \"coughing\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"shortness of breath\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"fatigue\", \"tiredness\", \"loss of energy\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"sore\", \"sore throat\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"congestion\", \"runny\", \"nose\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"muscle\", \"body\", \"aches\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"nausea\", \"vomiting\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"diarrhea\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"chills\", \"shivering\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"pressure on chest\", \"weight on my chest\", \"pressure in head\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"pink eye\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"rash\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"fainting\", \"dizziness\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"seizures\", \"seizure\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"confusion\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"abdominal pain\", \"stomach pain\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"loss of appetite\", \"not hungry\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"muscle\", \"joint\", \"joint pain\", \"muscle pain\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"difficulty sleeping\", \"insomnia\", \"can't sleep\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"feeling disoriented\", \"disoriented\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"numbness\", \"tingling\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"chest pain\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"swelling\", \"edema\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"bruising\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"loss of coordination\", \"uncoordinated\", \"poor balance\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"difficulty speaking\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"frequent urination\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"blood in urine\", \"hematuria\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"skin discoloration\", \"discoloration\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"decreased urination\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"swollen glands\", \"enlarged glands\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"hair loss\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"chapped lips\", \"chapped\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"puffy eyes\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"weight gain\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"hoarse voice\", \"hoarse\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"mood changes\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"cognitive issues\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"leg swelling\", \"swelling\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"hair thinning\", \"thinning\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"dry skin\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"weakness\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"tremors\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"depression\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"anxiety\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"irritability\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"insomnia\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"feeling cold\", \"feel cold\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"feeling hot\", \"feel hot\", \"sweats\", \"sweaty\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"difficulty breathing\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"chest tightness\", \"tightness in chest\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"palpitations\", \"heart palpitations\", \"fluttering\", \"racing heart\", \n",
    "                       \"heart fluttering\", \"irregular heartbeat\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"lightheadedness\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"dizziness\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"severe headache\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"stroke\", \"heart attack\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"vision loss\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"paralysis\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"aphasia\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"weakness in arms\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"weakness in legs\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"facial droop\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"slurred speech\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"difficulty swallowing\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"decreased sense of smell\", \"sense of smell\", \"smell\", \"loss of smell\"]}}],\n",
    "    [{\"LOWER\": {\"IN\": [\"decreased sense of taste\", \"taste\", \n",
    "                       \"sense of taste\", \"loss of taste\", \"no taste\"]}}],\n",
    "]\n",
    "\n",
    "grouped_symptoms = {\n",
    "    \"fever\": [\"fever\", \"high temperature\"],\n",
    "    \"headache\": [\"headache\", \"migraine\"],\n",
    "    \"cough\": [\"cough\", \"coughing\"],\n",
    "    \"shortness_of_breath\": [\"shortness of breath\"],\n",
    "    \"fatigue\": [\"fatigue\", \"tiredness\", \"loss of energy\"],\n",
    "    \"sore_throat\": [\"sore\", \"sore throat\"],\n",
    "    \"congestion\": [\"congestion\", \"runny nose\"],\n",
    "    \"muscle_aches\": [\"muscle\", \"body aches\"],\n",
    "    \"nausea_vomiting\": [\"nausea\", \"vomiting\"],\n",
    "    \"diarrhea\": [\"diarrhea\"],\n",
    "    \"chills\": [\"chills\", \"shivering\"],\n",
    "    \"chest_head_pressure\": [\"pressure on chest\", \"weight on my chest\", \"pressure in head\"],\n",
    "    \"pink_eye\": [\"pink eye\"],\n",
    "    \"rash\": [\"rash\"],\n",
    "    \"dizziness\": [\"fainting\", \"dizziness\"],\n",
    "    \"seizures\": [\"seizures\", \"seizure\"],\n",
    "    \"confusion\": [\"confusion\"],\n",
    "    \"abdominal_pain\": [\"abdominal pain\", \"stomach pain\"],\n",
    "    \"loss_of_appetite\": [\"loss of appetite\", \"not hungry\"],\n",
    "    \"muscle_joint_pain\": [\"muscle\", \"joint pain\"],\n",
    "    \"difficulty_sleeping\": [\"difficulty sleeping\", \"insomnia\", \"can't sleep\"],\n",
    "    \"feeling_disoriented\": [\"feeling disoriented\", \"disoriented\"],\n",
    "    \"numbness_tingling\": [\"numbness\", \"tingling\"],\n",
    "    \"chest_pain\": [\"chest pain\"],\n",
    "    \"swelling_edema\": [\"swelling\", \"edema\"],\n",
    "    \"bruising\": [\"bruising\"],\n",
    "    \"loss_of_coordination\": [\"loss of coordination\", \"uncoordinated\", \"poor balance\"],\n",
    "    \"difficulty_speaking\": [\"difficulty speaking\"],\n",
    "    \"frequent_urination\": [\"frequent urination\"],\n",
    "    \"blood_in_urine\": [\"blood in urine\", \"hematuria\"],\n",
    "    \"skin_discoloration\": [\"skin discoloration\", \"discoloration\"],\n",
    "    \"decreased_urination\": [\"decreased urination\"],\n",
    "    \"swollen_glands\": [\"swollen glands\", \"enlarged glands\"],\n",
    "    \"hair_loss\": [\"hair loss\"],\n",
    "    \"chapped_lips\": [\"chapped lips\", \"chapped\"],\n",
    "    \"puffy_eyes\": [\"puffy eyes\"],\n",
    "    \"weight_gain\": [\"weight gain\"],\n",
    "    \"hoarse_voice\": [\"hoarse voice\", \"hoarse\"],\n",
    "    \"mood_changes\": [\"mood changes\"],\n",
    "    \"cognitive_issues\": [\"cognitive issues\"],\n",
    "    \"leg_swelling\": [\"leg swelling\"],\n",
    "    \"hair_thinning\": [\"hair thinning\", \"thinning\"],\n",
    "    \"dry_skin\": [\"dry skin\"],\n",
    "    \"weakness\": [\"weakness\"],\n",
    "    \"tremors\": [\"tremors\"],\n",
    "    \"depression\": [\"depression\"],\n",
    "    \"anxiety\": [\"anxiety\"],\n",
    "    \"irritability\": [\"irritability\"],\n",
    "    \"insomnia\": [\"insomnia\"],\n",
    "    \"feeling_cold\": [\"feeling cold\", \"feel cold\"],\n",
    "    \"feeling_hot\": [\"feeling hot\", \"feel hot\", \"sweats\", \"sweaty\"],\n",
    "    \"difficulty_breathing\": [\"difficulty breathing\"],\n",
    "    \"chest_tightness\": [\"chest tightness\", \"tightness in chest\"],\n",
    "    \"palpitations\": [\"palpitations\", \"heart palpitations\", \"fluttering\", \"racing heart\", \"heart fluttering\", \"irregular heartbeat\"],\n",
    "    \"lightheadedness\": [\"lightheadedness\"],\n",
    "    \"severe_headache\": [\"severe headache\"],\n",
    "    \"stroke_heart_attack\": [\"stroke\", \"heart attack\"],\n",
    "    \"vision_loss\": [\"vision loss\"],\n",
    "    \"paralysis\": [\"paralysis\"],\n",
    "    \"aphasia\": [\"aphasia\"],\n",
    "    \"weakness_in_arms\": [\"weakness in arms\"],\n",
    "    \"weakness_in_legs\": [\"weakness in legs\"],\n",
    "    \"facial_droop\": [\"facial droop\"],\n",
    "    \"slurred_speech\": [\"slurred speech\"],\n",
    "    \"difficulty_swallowing\": [\"difficulty swallowing\"],\n",
    "    \"decreased_sense_of_smell\": [\"decreased sense of smell\", \"sense of smell\", \"smell\", \"loss of smell\"],\n",
    "    \"decreased_sense_of_taste\": [\"decreased sense of taste\", \"taste\", \"sense of taste\", \"loss of taste\", \"no taste\"]\n",
    "}\n",
    "\n",
    "matcher.add(\"COVID_SYMPTOMS\", covid_symptoms)\n",
    "\n",
    "weekly_text = pd.read_pickle('weekly_tf_idf.pkl')\n",
    "weekly_text['symptoms'] = None\n",
    "\n",
    "for index, row in weekly_text.iloc[::-1].iterrows():\n",
    "    if weekly_text.at[index, 'symptoms'] == None:\n",
    "        symptoms = set()\n",
    "        doc = nlp(row['textProcessed'])\n",
    "\n",
    "        matches = matcher(doc)\n",
    "\n",
    "        # Extract matched spans\n",
    "        for match_id, start, end in matches:\n",
    "            matched_span = doc[start:end]\n",
    "\n",
    "            # Check if the matched span text is in any grouped symptom set\n",
    "            for symptom_group, symptom_set in grouped_symptoms.items():\n",
    "                if matched_span.text.lower() in symptom_set:\n",
    "                    symptoms.add(symptom_group)\n",
    "                    break  # Stop searching for other groups once found\n",
    "\n",
    "        weekly_text.at[index, 'symptoms'] = symptoms\n",
    "\n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')\n",
    "weekly_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9734f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_df.to_pickle('updated_testing_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5ffe8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekAuthored</th>\n",
       "      <th>textProcessed</th>\n",
       "      <th>count</th>\n",
       "      <th>tfIdfMatrix</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>this week's review of the covid-19 pandemic in...</td>\n",
       "      <td>39</td>\n",
       "      <td>{'week': 0.010084212298055277, ''s': 0.0134456...</td>\n",
       "      <td>{decreased_sense_of_smell, fever, sore_throat,...</td>\n",
       "      <td>[months, blood, week, days, guidelines, doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>officially part of team canada i didn't realiz...</td>\n",
       "      <td>247</td>\n",
       "      <td>{'attend': 0.0025816384077358536, 'music': 0.0...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "      <td>[spread, learn, hepatitis, reduce, individuals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>hi everyone i just want to share something i w...</td>\n",
       "      <td>210</td>\n",
       "      <td>{'gleyber': 0.009225490200071285, 'torres': 0....</td>\n",
       "      <td>{decreased_sense_of_taste, confusion, depressi...</td>\n",
       "      <td>[tmzlive, trump loyalty, laps, flunked #, # tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>5 months later and saw a grand baby graduation...</td>\n",
       "      <td>222</td>\n",
       "      <td>{'emory': 0.021803662289033455, 'university': ...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "      <td>[children, initially, initially admitted, body...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>student speaks on the ingraham angle on how sh...</td>\n",
       "      <td>212</td>\n",
       "      <td>{'#': 0.041151703948002334, 'staysafe': 0.0030...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "      <td>[result, visitors, puerto rico, puerto, rico, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>a new study warns that men with lower testoste...</td>\n",
       "      <td>213</td>\n",
       "      <td>{'@': 0.0839901855207587, 'kff': 0.00266710149...</td>\n",
       "      <td>{decreased_sense_of_taste, stroke_heart_attack...</td>\n",
       "      <td>[rep david, david clark, david, clark, memoria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>i had the virus back in december 2019 i did no...</td>\n",
       "      <td>199</td>\n",
       "      <td>{'#': 0.06802288537076036, 'fortheloveofdata':...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "      <td>[cruise, passengers, prior, kids, data, childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>for decades fda guidelines have limited gay an...</td>\n",
       "      <td>246</td>\n",
       "      <td>{'self-registration': 0.004111668283926706, 'p...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "      <td>[tara, cruise, center, ship, delta, cruise shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>has this been happening to anyone i had covid ...</td>\n",
       "      <td>205</td>\n",
       "      <td>{'info': 0.008339970096233131, ',': 0.00407137...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, confusion, st...</td>\n",
       "      <td>[children, players, kids helping, children 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>healthcare providers and pharmacies continue t...</td>\n",
       "      <td>209</td>\n",
       "      <td>{'learn': 0.007383854919684327, '#': 0.0599558...</td>\n",
       "      <td>{decreased_sense_of_taste, rash, stroke_heart_...</td>\n",
       "      <td>[cruise, week, senate, senate hearing, county,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekAuthored                                      textProcessed  count  \\\n",
       "0   2021-05-02  this week's review of the covid-19 pandemic in...     39   \n",
       "1   2021-05-09  officially part of team canada i didn't realiz...    247   \n",
       "2   2021-05-16  hi everyone i just want to share something i w...    210   \n",
       "3   2021-05-23  5 months later and saw a grand baby graduation...    222   \n",
       "4   2021-05-30  student speaks on the ingraham angle on how sh...    212   \n",
       "5   2021-06-06  a new study warns that men with lower testoste...    213   \n",
       "6   2021-06-13  i had the virus back in december 2019 i did no...    199   \n",
       "7   2021-06-20  for decades fda guidelines have limited gay an...    246   \n",
       "8   2021-06-27  has this been happening to anyone i had covid ...    205   \n",
       "9   2021-07-04  healthcare providers and pharmacies continue t...    209   \n",
       "\n",
       "                                         tfIdfMatrix  \\\n",
       "0  {'week': 0.010084212298055277, ''s': 0.0134456...   \n",
       "1  {'attend': 0.0025816384077358536, 'music': 0.0...   \n",
       "2  {'gleyber': 0.009225490200071285, 'torres': 0....   \n",
       "3  {'emory': 0.021803662289033455, 'university': ...   \n",
       "4  {'#': 0.041151703948002334, 'staysafe': 0.0030...   \n",
       "5  {'@': 0.0839901855207587, 'kff': 0.00266710149...   \n",
       "6  {'#': 0.06802288537076036, 'fortheloveofdata':...   \n",
       "7  {'self-registration': 0.004111668283926706, 'p...   \n",
       "8  {'info': 0.008339970096233131, ',': 0.00407137...   \n",
       "9  {'learn': 0.007383854919684327, '#': 0.0599558...   \n",
       "\n",
       "                                            symptoms  \\\n",
       "0  {decreased_sense_of_smell, fever, sore_throat,...   \n",
       "1  {decreased_sense_of_taste, rash, confusion, st...   \n",
       "2  {decreased_sense_of_taste, confusion, depressi...   \n",
       "3  {decreased_sense_of_taste, rash, stroke_heart_...   \n",
       "4  {decreased_sense_of_taste, rash, stroke_heart_...   \n",
       "5  {decreased_sense_of_taste, stroke_heart_attack...   \n",
       "6  {decreased_sense_of_taste, rash, confusion, st...   \n",
       "7  {decreased_sense_of_taste, rash, stroke_heart_...   \n",
       "8  {decreased_sense_of_taste, rash, confusion, st...   \n",
       "9  {decreased_sense_of_taste, rash, stroke_heart_...   \n",
       "\n",
       "                                              values  \n",
       "0  [months, blood, week, days, guidelines, doctor...  \n",
       "1  [spread, learn, hepatitis, reduce, individuals...  \n",
       "2  [tmzlive, trump loyalty, laps, flunked #, # tr...  \n",
       "3  [children, initially, initially admitted, body...  \n",
       "4  [result, visitors, puerto rico, puerto, rico, ...  \n",
       "5  [rep david, david clark, david, clark, memoria...  \n",
       "6  [cruise, passengers, prior, kids, data, childr...  \n",
       "7  [tara, cruise, center, ship, delta, cruise shi...  \n",
       "8  [children, players, kids helping, children 11,...  \n",
       "9  [cruise, week, senate, senate hearing, county,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_df = pd.read_pickle('weekly_tf_idf.pkl')\n",
    "weekly_df['values'] = [[] for _ in range(len(weekly_text))]\n",
    "more_stopwords = [\n",
    "    'covid',\n",
    "    'coronavirus',\n",
    "    'corona',\n",
    "    'rona',\n",
    "    'covid-19',\n",
    "    'tested',\n",
    "    'testing',\n",
    "    'test',\n",
    "    'tests',\n",
    "    'symptoms',\n",
    "    'positive',\n",
    "    'negative',\n",
    "    'para',\n",
    "    'vaccine',\n",
    "    'vaccines',\n",
    "    'vaccinated',\n",
    "    'vaxxed',\n",
    "    'virus'\n",
    "    'tests',\n",
    "    'people',\n",
    "    'health',\n",
    "    'pandemic',\n",
    "    'virus',\n",
    "    'sars-cov-2',\n",
    "    'doctor',\n",
    "    'covid19',\n",
    "    'vaccination',\n",
    "    'vaccinations',\n",
    "    'rt @',\n",
    "    '-- --',\n",
    "    '',\n",
    "    \"I'm\", \n",
    "    r'\\u', \n",
    "    '&', \n",
    "    'amp',\n",
    "    'https']\n",
    "    \n",
    "# filtered_list = list(set(sorted_dict).difference(stopwords))\n",
    "    \n",
    "weekly_text['values'] = None\n",
    "\n",
    "for index, row in weekly_df.iterrows():\n",
    "    # Remove one-character words or strange numbers..\n",
    "    items = row['tfIdfMatrix'].items()\n",
    "    matrix_modified = {}\n",
    "    for key, value in items:  \n",
    "        if not key.isdigit() and len(key) > 3:\n",
    "            # Remove stopwords\n",
    "            words = key.lower().split()\n",
    "            \n",
    "            if all(word not in more_stopwords for word in words):\n",
    "                matrix_modified[key] = value\n",
    "\n",
    "    weekly_df.at[index, 'tfIdfMatrix'] = matrix_modified\n",
    "\n",
    "    sorted_df = pd.DataFrame.from_dict(matrix_modified, orient='index', columns=['tfIdfValue'])\n",
    "    sorted_df = sorted_df.reset_index()\n",
    "    sorted_df = sorted_df.rename(columns={'index' : 'keyword'})\n",
    "    sorted_df = sorted_df.sort_values(by='tfIdfValue', ascending=False)\n",
    "    sorted_dict = sorted_df['keyword'].tolist()\n",
    "    \n",
    "    for item in more_stopwords:\n",
    "        if item in sorted_dict:\n",
    "            sorted_dict.remove(item)\n",
    "    \n",
    "    sorted_dict = [item for item in sorted_dict if item]\n",
    "    \n",
    "    sorted_dict = sorted_dict[:20] # keep only the first 20 values\n",
    "    # print(sorted_dict)\n",
    "    weekly_text.at[index, 'values'] = sorted_dict\n",
    "    \n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')\n",
    "\n",
    "weekly_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b72f7fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(weekly_text['values'].tolist(), index=weekly_text['weekAuthored'])\n",
    "\n",
    "words_df = words_df.reset_index()\n",
    "words_df.to_pickle('keywords.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa5b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID-19 Long Haulers Support' 'Survivor Corps' 'Vaccines save lives'\n",
      " 'COVID-19 Novel Coronavirus FACTS' '¡MÉDICOS POR LA VERDAD!'\n",
      " 'Black News Network (BNN)'\n",
      " 'COVID19: Real Talk from Health Care Workers around the Globe'\n",
      " 'Black Educators' 'Covid Wellness Clinic'\n",
      " 'Coronavirus Updates for: Statesboro, Georgia & Surrounding Counties'\n",
      " 'Athens GA COVID-19 Resources and Discussion' 'Georgia Trump Republicans'\n",
      " \"Skip Mason's Vanishing Black Atlanta History\" 'DeKalb Strong'\n",
      " 'COVID-19 Watch North GA w/ Help & Resources'\n",
      " 'Albany, GA Area Happenings Over 21'\n",
      " 'Albany GA: Home Is Where The Heart Is'\n",
      " 'Type 1 Diabetes Recipes & Food Ideas'\n",
      " 'Kimono My House (Virtual House Concerts)'\n",
      " 'Dank Diabetes Memes Diabuddies' 'America First Tea Party'\n",
      " 'The Prayer Wall' 'TERMINÓ 🧑\\u200d🦽🧑\\u200d🦽🧑\\u200d🦽🧑\\u200d🦽'\n",
      " 'Coronavirus Updates from NBC News']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekAuthored</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>months</td>\n",
       "      <td>blood</td>\n",
       "      <td>week</td>\n",
       "      <td>days</td>\n",
       "      <td>guidelines</td>\n",
       "      <td>doctors</td>\n",
       "      <td>issues</td>\n",
       "      <td>antibodies</td>\n",
       "      <td>infected</td>\n",
       "      <td>...</td>\n",
       "      <td>started</td>\n",
       "      <td>month</td>\n",
       "      <td>brooks</td>\n",
       "      <td>hospital</td>\n",
       "      <td>april</td>\n",
       "      <td>feeling</td>\n",
       "      <td>fatigue</td>\n",
       "      <td>weeks</td>\n",
       "      <td>haulers</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>spread</td>\n",
       "      <td>learn</td>\n",
       "      <td>hepatitis</td>\n",
       "      <td>reduce</td>\n",
       "      <td>individuals</td>\n",
       "      <td>daily</td>\n",
       "      <td>patients</td>\n",
       "      <td>georgia</td>\n",
       "      <td>antigen</td>\n",
       "      <td>...</td>\n",
       "      <td>lowest</td>\n",
       "      <td>united</td>\n",
       "      <td>hhsgov</td>\n",
       "      <td>act_covid</td>\n",
       "      <td>individuals living</td>\n",
       "      <td># covidtesting</td>\n",
       "      <td>@ act_covid</td>\n",
       "      <td># antibody</td>\n",
       "      <td>july</td>\n",
       "      <td>hhsgov resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>tmzlive</td>\n",
       "      <td>trump loyalty</td>\n",
       "      <td>laps</td>\n",
       "      <td>flunked #</td>\n",
       "      <td># trump</td>\n",
       "      <td>talladega superspeedway</td>\n",
       "      <td>afterward​</td>\n",
       "      <td>track</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>...</td>\n",
       "      <td>recipients</td>\n",
       "      <td>granting</td>\n",
       "      <td>hosting</td>\n",
       "      <td>superspeedway</td>\n",
       "      <td>talladega</td>\n",
       "      <td>lizcheney flunked</td>\n",
       "      <td>lizcheney</td>\n",
       "      <td>adamkinzinger</td>\n",
       "      <td># princeharry</td>\n",
       "      <td>flunked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>children</td>\n",
       "      <td>initially</td>\n",
       "      <td>initially admitted</td>\n",
       "      <td>body​</td>\n",
       "      <td>rite</td>\n",
       "      <td>scottish</td>\n",
       "      <td>qiana</td>\n",
       "      <td>qiana bigsby</td>\n",
       "      <td>son ziggy</td>\n",
       "      <td>...</td>\n",
       "      <td>rite hospital</td>\n",
       "      <td>bigsby</td>\n",
       "      <td>ziggy</td>\n",
       "      <td>toll</td>\n",
       "      <td>admitted</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>travelers</td>\n",
       "      <td>covid-19​</td>\n",
       "      <td>maher</td>\n",
       "      <td>flights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>result</td>\n",
       "      <td>visitors</td>\n",
       "      <td>puerto rico</td>\n",
       "      <td>puerto</td>\n",
       "      <td>rico</td>\n",
       "      <td>enter</td>\n",
       "      <td>infections</td>\n",
       "      <td>force</td>\n",
       "      <td>nightly</td>\n",
       "      <td>...</td>\n",
       "      <td>island</td>\n",
       "      <td>georgia</td>\n",
       "      <td>miguel</td>\n",
       "      <td>southern</td>\n",
       "      <td>spread</td>\n",
       "      <td>masks</td>\n",
       "      <td>city</td>\n",
       "      <td>residents</td>\n",
       "      <td>difference</td>\n",
       "      <td>gadph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>rep david</td>\n",
       "      <td>david clark</td>\n",
       "      <td>david</td>\n",
       "      <td>clark</td>\n",
       "      <td>memorial</td>\n",
       "      <td>refusing</td>\n",
       "      <td>national</td>\n",
       "      <td>headlines</td>\n",
       "      <td>national headlines</td>\n",
       "      <td>...</td>\n",
       "      <td>kicked</td>\n",
       "      <td>rahm</td>\n",
       "      <td>buford</td>\n",
       "      <td>house chamber</td>\n",
       "      <td>house</td>\n",
       "      <td>january</td>\n",
       "      <td>expert</td>\n",
       "      <td>normalcy</td>\n",
       "      <td>jon rahm</td>\n",
       "      <td>celebrating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>cruise</td>\n",
       "      <td>passengers</td>\n",
       "      <td>prior</td>\n",
       "      <td>kids</td>\n",
       "      <td>data</td>\n",
       "      <td>children</td>\n",
       "      <td>time</td>\n",
       "      <td>risk</td>\n",
       "      <td>return</td>\n",
       "      <td>...</td>\n",
       "      <td>prior infection</td>\n",
       "      <td>reliable</td>\n",
       "      <td>week</td>\n",
       "      <td>infection</td>\n",
       "      <td>cards</td>\n",
       "      <td>residents</td>\n",
       "      <td>claims</td>\n",
       "      <td>guests</td>\n",
       "      <td>antigen</td>\n",
       "      <td>rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-20</td>\n",
       "      <td>tara</td>\n",
       "      <td>cruise</td>\n",
       "      <td>center</td>\n",
       "      <td>ship</td>\n",
       "      <td>delta</td>\n",
       "      <td>cruise ship</td>\n",
       "      <td>crew</td>\n",
       "      <td>georgia</td>\n",
       "      <td>royal caribbean</td>\n",
       "      <td>...</td>\n",
       "      <td>public</td>\n",
       "      <td>caribbean</td>\n",
       "      <td>community</td>\n",
       "      <td>coach</td>\n",
       "      <td>go-to</td>\n",
       "      <td>coweta</td>\n",
       "      <td>mako</td>\n",
       "      <td>passengers</td>\n",
       "      <td>antigen</td>\n",
       "      <td>2′s wendy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>children</td>\n",
       "      <td>players</td>\n",
       "      <td>kids helping</td>\n",
       "      <td>children 11</td>\n",
       "      <td>east</td>\n",
       "      <td>3-year-old</td>\n",
       "      <td>atlanta 3-year-old</td>\n",
       "      <td>east atlanta</td>\n",
       "      <td>helping</td>\n",
       "      <td>...</td>\n",
       "      <td>kids</td>\n",
       "      <td>thousands</td>\n",
       "      <td>approved</td>\n",
       "      <td>danish</td>\n",
       "      <td>championship</td>\n",
       "      <td>championship soccer</td>\n",
       "      <td>attending</td>\n",
       "      <td>soccer games</td>\n",
       "      <td>european</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-07-04</td>\n",
       "      <td>cruise</td>\n",
       "      <td>week</td>\n",
       "      <td>senate</td>\n",
       "      <td>senate hearing</td>\n",
       "      <td>county</td>\n",
       "      <td>hearing</td>\n",
       "      <td>texas</td>\n",
       "      <td>unvaccinated</td>\n",
       "      <td>camp</td>\n",
       "      <td>...</td>\n",
       "      <td>dr susan</td>\n",
       "      <td># texas</td>\n",
       "      <td># theysurvivedcovid</td>\n",
       "      <td>cobb</td>\n",
       "      <td>susan</td>\n",
       "      <td>theysurvivedcovid</td>\n",
       "      <td>learn</td>\n",
       "      <td>church</td>\n",
       "      <td>center</td>\n",
       "      <td>north</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekAuthored          0              1                   2               3  \\\n",
       "0   2021-05-02     months          blood                week            days   \n",
       "1   2021-05-09     spread          learn           hepatitis          reduce   \n",
       "2   2021-05-16    tmzlive  trump loyalty                laps       flunked #   \n",
       "3   2021-05-23   children      initially  initially admitted           body​   \n",
       "4   2021-05-30     result       visitors         puerto rico          puerto   \n",
       "5   2021-06-06  rep david    david clark               david           clark   \n",
       "6   2021-06-13     cruise     passengers               prior            kids   \n",
       "7   2021-06-20       tara         cruise              center            ship   \n",
       "8   2021-06-27   children        players        kids helping     children 11   \n",
       "9   2021-07-04     cruise           week              senate  senate hearing   \n",
       "\n",
       "             4                        5                   6             7  \\\n",
       "0   guidelines                  doctors              issues    antibodies   \n",
       "1  individuals                    daily            patients       georgia   \n",
       "2      # trump  talladega superspeedway          afterward​         track   \n",
       "3         rite                 scottish               qiana  qiana bigsby   \n",
       "4         rico                    enter          infections         force   \n",
       "5     memorial                 refusing            national     headlines   \n",
       "6         data                 children                time          risk   \n",
       "7        delta              cruise ship                crew       georgia   \n",
       "8         east               3-year-old  atlanta 3-year-old  east atlanta   \n",
       "9       county                  hearing               texas  unvaccinated   \n",
       "\n",
       "                    8  ...               10         11                   12  \\\n",
       "0            infected  ...          started      month               brooks   \n",
       "1             antigen  ...           lowest     united               hhsgov   \n",
       "2         opportunity  ...       recipients   granting              hosting   \n",
       "3           son ziggy  ...    rite hospital     bigsby                ziggy   \n",
       "4             nightly  ...           island    georgia               miguel   \n",
       "5  national headlines  ...           kicked       rahm               buford   \n",
       "6              return  ...  prior infection   reliable                 week   \n",
       "7     royal caribbean  ...           public  caribbean            community   \n",
       "8             helping  ...             kids  thousands             approved   \n",
       "9                camp  ...         dr susan    # texas  # theysurvivedcovid   \n",
       "\n",
       "              13                  14                   15           16  \\\n",
       "0       hospital               april              feeling      fatigue   \n",
       "1      act_covid  individuals living       # covidtesting  @ act_covid   \n",
       "2  superspeedway           talladega    lizcheney flunked    lizcheney   \n",
       "3           toll            admitted              atlanta    travelers   \n",
       "4       southern              spread                masks         city   \n",
       "5  house chamber               house              january       expert   \n",
       "6      infection               cards            residents       claims   \n",
       "7          coach               go-to               coweta         mako   \n",
       "8         danish        championship  championship soccer    attending   \n",
       "9           cobb               susan    theysurvivedcovid        learn   \n",
       "\n",
       "              17             18                19  \n",
       "0          weeks        haulers             issue  \n",
       "1     # antibody           july  hhsgov resources  \n",
       "2  adamkinzinger  # princeharry           flunked  \n",
       "3      covid-19​          maher           flights  \n",
       "4      residents     difference             gadph  \n",
       "5       normalcy       jon rahm       celebrating  \n",
       "6         guests        antigen             rapid  \n",
       "7     passengers        antigen         2′s wendy  \n",
       "8   soccer games       european            soccer  \n",
       "9         church         center             north  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_df = pd.read_pickle('updated_testing_data.pkl')\n",
    "list(sm_df['author'].unique())\n",
    "\n",
    "facebook_df = sm_df[(sm_df['platform'] == 'facebook') & \n",
    "                    sm_df['raw'].apply(lambda x: 'account' in x \n",
    "                   and x['account'].get('accountType') == 'facebook_group' \n",
    "                                       if isinstance(x, dict) else False)]\n",
    "\n",
    "print(facebook_df['author'].unique())\n",
    "\n",
    "words_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
