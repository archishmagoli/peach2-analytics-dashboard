{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bf55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import MWETokenizer\n",
    "import math\n",
    "from nltk.util import ngrams\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b26cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in the data\n",
    "df1 = pd.read_pickle('testing_data_static_2022-04-10.pkl') # extract pkl file 1\n",
    "df2 = pd.read_pickle('testing_data_update_2022-04-10_2023-04-10.pkl') # extract pkl file 2\n",
    "testing_data = pd.concat([df1,df2],ignore_index=True)\n",
    "testing_data = testing_data.sort_values(by='authoredAt').reset_index(drop=True)\n",
    "testing_data.to_pickle('updated_testing_data.pkl')\n",
    "sm_df = testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8778dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis (VADER)\n",
    "# authoredAt column datetime manipulation for timeseries grouping\n",
    "sm_df['authoredAt'] = pd.to_datetime(sm_df['authoredAt'])\n",
    "sm_df['authoredAt'] = sm_df['authoredAt'].dt.date.astype('datetime64[ns]')\n",
    "sm_df['weekAuthored'] = sm_df['authoredAt'].dt.isocalendar().week\n",
    "\n",
    "platform_list = sm_df['platform'].unique()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sm_df['negative'] = None\n",
    "sm_df['positive'] = None\n",
    "sm_df['compound'] = None\n",
    "sm_df['sentiment'] = None\n",
    "\n",
    "index = len(sm_df) - 1\n",
    "while index >= 0:\n",
    "    timeNotValid = False\n",
    "    sentimentNotValid = False\n",
    "    \n",
    "    if pd.isnull(sm_df.at[index, 'weekAuthored']) or not isinstance(sm_df.at[index, 'authoredAt'], pd.Timestamp):\n",
    "        # Check if 'weekAuthored' is null or 'authoredAt' is not of datetime type\n",
    "        # If any of the conditions are true, update the values\n",
    "        sm_df.at[index, 'authoredAt'] = pd.to_datetime(sm_df.at[index, 'authoredAt'], errors='coerce')\n",
    "        sm_df.at[index, 'authoredAt'] = sm_df.at[index, 'authoredAt'].date().astype('datetime64[ns]')\n",
    "        timeNotValid = True\n",
    "    \n",
    "    if (sm_df.at[index, 'negative'] is None) or (sm_df.at[index, 'positive'] is None) \\\n",
    "       or (sm_df.at[index, 'neutral'] is None) or (sm_df.at[index, 'compound'] is None):\n",
    "        text = sm_df.at[index, 'content']\n",
    "        sm_df.at[index, 'sentiment'] = analyzer.polarity_scores(text)\n",
    "        sm_df.at[index, 'negative'] = sm_df.at[index, 'sentiment']['neg']\n",
    "        sm_df.at[index, 'positive'] = sm_df.at[index, 'sentiment']['pos']\n",
    "        sm_df.at[index, 'neutral'] = sm_df.at[index, 'sentiment']['neu']\n",
    "        sm_df.at[index, 'compound'] = sm_df.at[index, 'sentiment']['compound']\n",
    "        sentimentNotValid = True\n",
    "\n",
    "    if not timeNotValid and not sentimentNotValid:\n",
    "        break\n",
    "        \n",
    "    index -= 1\n",
    "    \n",
    "# One-Hot Encoding Account Labels\n",
    "unique_values = set(val for sublist in sm_df['labels'] for val in sublist)\n",
    "# print(unique_values)\n",
    "for value in unique_values:\n",
    "    sm_df[value] = sm_df['labels'].apply(lambda x: 1 if value in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34a31c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = {\n",
    "    \"'ll\", \"'tis\", \"'twas\", \"'ve\", \"10\", \"39\", \"a\", \"a's\", \"able\", \"ableabout\", \"about\", \"above\", \"abroad\",\n",
    "    \"abst\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\",\n",
    "    \"adopted\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\",\n",
    "    \"ago\", \"ah\", \"ahead\", \"ai\", \"ain't\", \"aint\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\",\n",
    "    \"alongside\", \"already\", \"also\", \"although\", \"always\", \"am\", \"amid\", \"amidst\", \"among\", \"amongst\", \"amoungst\",\n",
    "    \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\",\n",
    "    \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\",\n",
    "    \"approximately\", \"aq\", \"ar\", \"are\", \"area\", \"areas\", \"aren\", \"aren't\", \"arent\", \"arise\", \"around\", \"arpa\",\n",
    "    \"as\", \"aside\", \"ask\", \"asked\", \"asking\", \"asks\", \"associated\", \"at\", \"au\", \"auth\", \"available\", \"aw\", \"away\",\n",
    "    \"awfully\", \"az\", \"b\", \"ba\", \"back\", \"backed\", \"backing\", \"backs\", \"backward\", \"backwards\", \"bb\", \"bd\", \"be\",\n",
    "    \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"began\", \"begin\",\n",
    "    \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"beings\", \"believe\", \"below\", \"beside\", \"besides\",\n",
    "    \"best\", \"better\", \"between\", \"beyond\", \"bf\", \"bg\", \"bh\", \"bi\", \"big\", \"bill\", \"billion\", \"biol\", \"bj\", \"bm\",\n",
    "    \"bn\", \"bo\", \"both\", \"bottom\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"but\", \"buy\", \"bv\", \"bw\", \"by\", \"bz\",\n",
    "    \"c\", \"c'mon\", \"c's\", \"ca\", \"call\", \"came\", \"can\", \"can't\", \"cannot\", \"cant\", \"caption\", \"case\", \"cases\",\n",
    "    \"cause\", \"causes\", \"cc\", \"cd\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"ck\", \"cl\", \"clear\",\n",
    "    \"clearly\", \"click\", \"cm\", \"cmon\", \"cn\", \"co\", \"co.\", \"com\", \"come\", \"comes\", \"computer\", \"con\", \"concerning\",\n",
    "    \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"copy\", \"corresponding\",\n",
    "    \"could\", \"could've\", \"couldn\", \"couldn't\", \"couldnt\", \"course\", \"cr\", \"cry\", \"cs\", \"cu\", \"currently\", \"cv\",\n",
    "    \"cx\", \"cy\", \"cz\", \"d\", \"dare\", \"daren't\", \"darent\", \"date\", \"de\", \"dear\", \"definitely\", \"describe\", \"described\",\n",
    "    \"despite\", \"detail\", \"did\", \"didn\", \"didn't\", \"didnt\", \"differ\", \"different\", \"differently\", \"directly\", \"dj\",\n",
    "    \"dk\", \"dm\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doesnt\", \"doing\", \"don\", \"don't\", \"done\", \"dont\", \"doubtful\",\n",
    "    \"down\", \"downed\", \"downing\", \"downs\", \"downwards\", \"due\", \"during\", \"dz\", \"e\", \"each\", \"early\", \"ec\", \"ed\",\n",
    "    \"edu\", \"ee\", \"effect\", \"eg\", \"eh\", \"eight\", \"eighty\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"end\",\n",
    "    \"ended\", \"ending\", \"ends\", \"enough\", \"entirely\", \"er\", \"es\", \"especially\", \"et\", \"et-al\", \"etc\", \"even\",\n",
    "    \"evenly\", \"ever\", \"evermore\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\",\n",
    "    \"example\", \"except\", \"f\", \"face\", \"faces\", \"fact\", \"facts\", \"fairly\", \"far\", \"farther\", \"felt\", \"few\", \"fewer\",\n",
    "    \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fifty\", \"fify\", \"fill\", \"find\", \"finds\", \"fire\", \"first\", \"five\", \"fix\", \"fj\",\n",
    "    \"fk\", \"fm\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"forever\", \"former\", \"formerly\", \"forth\", \"forty\",\n",
    "    \"forward\", \"found\", \"four\", \"fr\", \"free\", \"from\", \"front\", \"full\", \"fully\", \"further\", \"furthered\",\n",
    "    \"furthering\", \"furthermore\", \"furthers\", \"fx\", \"g\", \"ga\", \"gave\", \"gb\", \"gd\", \"ge\", \"general\", \"generally\",\n",
    "    \"get\", \"gets\", \"getting\", \"gf\", \"gg\", \"gh\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gl\", \"gm\", \"gmt\", \"gn\",\n",
    "    \"go\", \"goes\", \"going\", \"gone\", \"good\", \"goods\", \"got\", \"gotten\", \"gov\", \"gp\", \"gq\", \"gr\", \"great\", \"greater\",\n",
    "    \"greatest\", \"greetings\", \"group\", \"grouped\", \"grouping\", \"groups\", \"gs\", \"gt\", \"gu\", \"gw\", \"gy\", \"h\", \"had\",\n",
    "    \"hadn\", \"hadn't\", \"hadnt\", \"half\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasn't\", \"hasnt\", \"have\", \"haven\",\n",
    "    \"haven't\", \"havent\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"hed\", \"hell\", \"hello\", \"help\",     \"hence\", \"her\", \"here\", \"here's\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hers\", \"herself\",\n",
    "    \"herse\", \"hes\", \"hi\", \"hid\", \"high\", \"higher\", \"highest\", \"him\", \"himself\", \"himse\", \"his\", \"hither\", \"hk\",\n",
    "    \"hm\", \"hn\", \"home\", \"homepage\", \"hopefully\", \"how\", \"how'd\", \"how'll\", \"how's\", \"howbeit\", \"however\", \"hr\",\n",
    "    \"ht\", \"htm\", \"html\", \"http\", \"hu\", \"hundred\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"i.e.\", \"id\", \"ie\", \"if\",\n",
    "    \"ignored\", \"ii\", \"il\", \"ill\", \"im\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\",\n",
    "    \"inc\", \"inc.\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"inside\",\n",
    "    \"insofar\", \"instead\", \"int\", \"interest\", \"interested\", \"interesting\", \"interests\", \"into\", \"invention\",\n",
    "    \"inward\", \"io\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"isnt\", \"it\", \"it'd\", \"it'll\", \"it's\", \"itd\", \"itll\",\n",
    "    \"its\", \"itself\", \"itse\", \"ive\", \"j\", \"je\", \"jm\", \"jo\", \"join\", \"jp\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\",\n",
    "    \"kept\", \"keys\", \"kg\", \"kh\", \"ki\", \"kind\", \"km\", \"kn\", \"knew\", \"know\", \"known\", \"knows\", \"kp\", \"kr\", \"kw\",\n",
    "    \"ky\", \"kz\", \"l\", \"la\", \"large\", \"largely\", \"last\", \"lately\", \"later\", \"latest\", \"latter\", \"latterly\", \"lb\",\n",
    "    \"lc\", \"least\", \"length\", \"less\", \"lest\", \"let\", \"let's\", \"lets\", \"li\", \"like\", \"liked\", \"likely\", \"likewise\",\n",
    "    \"line\", \"little\", \"lk\", \"ll\", \"long\", \"longer\", \"longest\", \"look\", \"looking\", \"looks\", \"low\", \"lower\", \"lr\",\n",
    "    \"ls\", \"lt\", \"ltd\", \"lu\", \"lv\", \"ly\", \"m\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"making\", \"man\", \"many\",\n",
    "    \"may\", \"maybe\", \"mayn't\", \"maynt\", \"mc\", \"md\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"member\",\n",
    "    \"members\", \"men\", \"merely\", \"mg\", \"mh\", \"microsoft\", \"might\", \"might've\", \"mightn\", \"mightn't\", \"mightnt\",\n",
    "    \"mil\", \"mill\", \"million\", \"mine\", \"minus\", \"miss\", \"mk\", \"ml\", \"mm\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\",\n",
    "    \"mostly\", \"move\", \"mp\", \"mq\", \"mr\", \"mrs\", \"ms\", \"msie\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"must've\",\n",
    "    \"mustn\", \"mustn't\", \"mustnt\", \"mv\", \"mw\", \"mx\", \"my\", \"myself\", \"myse\", \"mz\", \"n\", \"na\", \"name\", \"namely\",\n",
    "    \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needed\", \"needing\",\n",
    "    \"needn't\", \"neednt\", \"needs\", \"neither\", \"net\", \"netscape\", \"never\", \"neverf\", \"neverless\", \"nevertheless\",\n",
    "    \"new\", \"newer\", \"newest\", \"next\", \"nf\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nl\", \"no\", \"no-one\", \"nobody\", \"non\",\n",
    "    \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"notwithstanding\",\n",
    "    \"novel\", \"now\", \"nowhere\", \"np\", \"nr\", \"nu\", \"null\", \"number\", \"numbers\", \"nz\", \"o\", \"obtain\", \"obtained\",\n",
    "    \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"older\", \"oldest\", \"om\", \"omitted\", \"on\", \"once\",\n",
    "    \"one\", \"one's\", \"ones\", \"only\", \"onto\", \"open\", \"opened\", \"opening\", \"opens\", \"opposite\", \"or\", \"ord\", \"order\",\n",
    "    \"ordered\", \"ordering\", \"orders\", \"org\", \"other\", \"others\", \"otherwise\", \"ought\", \"oughtn't\", \"oughtnt\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"owing\", \"own\", \"p\", \"pa\", \"page\", \"pages\", \"part\",\n",
    "    \"parted\", \"particular\", \"particularly\", \"parting\", \"parts\", \"past\", \"pe\", \"per\", \"perhaps\", \"pf\", \"pg\", \"ph\",\n",
    "    \"pk\", \"pl\", \"place\", \"placed\", \"places\", \"please\", \"plus\", \"pm\", \"pmid\", \"pn\", \"point\", \"pointed\", \"pointing\",\n",
    "    \"points\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pr\", \"predominantly\", \"present\",\n",
    "    \"presented\", \"presenting\", \"presents\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"problem\",\n",
    "    \"problems\", \"promptly\", \"proud\", \"provided\", \"provides\", \"pt\", \"put\", \"puts\", \"pw\", \"py\", \"q\", \"qa\", \"que\",\n",
    "    \"quickly\", \"quite\", \"qv\", \"r\", \"ran\", \"rather\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\",\n",
    "    \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"reserved\",\n",
    "    \"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"ring\", \"ro\", \"room\", \"rooms\", \"round\", \"ru\",\n",
    "    \"run\", \"s\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sb\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\",\n",
    "    \"seconds\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"sees\", \"self\", \"selves\",\n",
    "    \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"seventy\", \"several\", \"sg\", \"sh\", \"shall\", \"shan't\",\n",
    "    \"shant\", \"she\", \"she'd\", \"she'll\", \"she's\", \"shed\", \"shell\", \"shes\", \"should\", \"should've\", \"shouldn\",\n",
    "    \"shouldn't\", \"shouldnt\", \"show\", \"showed\", \"showing\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"sides\",\n",
    "    \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"site\", \"six\", \"sixty\", \"sj\",\n",
    "    \"sk\", \"sl\", \"slightly\", \"sm\", \"small\", \"smaller\", \"smallest\", \"sn\", \"so\", \"some\", \"somebody\", \"someday\",\n",
    "    \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\",\n",
    "    \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sr\", \"st\", \"state\", \"states\", \"still\", \"stop\",\n",
    "    \"strongly\", \"su\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\",\n",
    "    \"sv\", \"sy\", \"system\", \"sz\", \"t\", \"t's\", \"take\", \"taken\", \"taking\", \"tc\", \"td\", \"tell\", \"ten\", \"tends\", \"test\",\n",
    "    \"text\", \"tf\", \"tg\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"that's\", \"that've\", \"thatll\",\n",
    "    \"thats\", \"thatve\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"there'd\",\n",
    "    \"there'll\", \"there're\", \"there's\", \"there've\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\",\n",
    "    \"therell\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"thereve\", \"these\", \"they\", \"they'd\",\n",
    "    \"they'll\", \"they're\", \"they've\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"thick\", \"thin\", \"thing\", \"things\",\n",
    "    \"think\", \"thinks\", \"third\", \"thirty\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\",\n",
    "    \"thought\", \"thoughts\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"til\", \"till\",\n",
    "    \"tip\", \"tis\", \"tj\", \"tk\", \"tm\", \"tn\", \"to\", \"today\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\",\n",
    "    \"tp\", \"tr\", \"tried\", \"tries\", \"trillion\", \"truly\", \"try\", \"trying\", \"ts\", \"tt\", \"turn\", \"turned\", \"turning\",\n",
    "    \"turns\", \"tv\", \"tw\", \"twas\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tz\", \"u\", \"ua\", \"ug\", \"uk\", \"um\", \"un\",\n",
    "    \"under\", \"underneath\", \"undoing\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"up\",\n",
    "    \"upon\", \"ups\", \"upwards\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\",\n",
    "    \"uucp\", \"uy\", \"uz\", \"v\", \"va\", \"value\", \"various\", \"vc\", \"ve\", \"versus\", \"very\", \"vg\", \"vi\", \"via\", \"viz\",\n",
    "    \"vn\", \"vol\", \"vols\", \"vs\", \"vu\", \"w\", \"want\", \"wanted\", \"wanting\", \"wants\", \"was\", \"wasn\", \"wasn't\", \"wasnt\",\n",
    "    \"way\", \"ways\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"web\", \"webpage\", \"website\", \"wed\", \"welcome\", \"well\",\n",
    "    \"wells\", \"went\", \"were\", \"weren\", \"weren't\", \"werent\", \"weve\", \"wf\", \"what\", \"what'd\", \"what'll\", \"what's\",\n",
    "    \"what've\", \"whatever\", \"whatll\", \"whats\", \"whatve\", \"when\", \"when'd\", \"when'll\", \"when's\", \"whence\",\n",
    "    \"whenever\", \"where\", \"where'd\", \"where'll\", \"where's\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\",\n",
    "    \"whereupon\", \"wherever\", \"whether\", \"which\", \"whichever\", \"while\", \"whilst\", \"whim\", \"whither\", \"who\",\n",
    "    \"who'd\", \"who'll\", \"who's\", \"whod\", \"whoever\", \"whole\", \"wholl\", \"whom\", \"whomever\", \"whos\", \"whose\", \"why\",\n",
    "    \"why'd\", \"why'll\", \"why's\", \"widely\", \"width\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"won\",\n",
    "    \"won't\", \"wonder\", \"wont\", \"words\", \"work\", \"worked\", \"working\", \"works\", \"world\", \"would\", \"would've\",\n",
    "    \"wouldn\", \"wouldn't\", \"wouldnt\", \"ws\", \"www\", \"x\", \"y\", \"ye\", \"year\", \"years\", \"yes\", \"yet\", \"you\", \"you'd\",\n",
    "    \"you'll\", \"you're\", \"you've\", \"youd\", \"youll\", \"young\", \"younger\", \"youngest\", \"your\", \"youre\", \"yours\",\n",
    "    \"yourself\", \"yourselves\", \"youve\", \"yt\", \"yu\", \"z\", \"za\", \"zero\", \"zm\", \"zr\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f61f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller function to generate TF-IDF Matrix\n",
    "def generate_matrix(sentences, documents):\n",
    "    sentences = nltk.sent_tokenize(text) # NLTK function\n",
    "    total_documents = documents\n",
    "\n",
    "    freq_matrix = _create_frequency_matrix(sentences)\n",
    "    tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "    documents_per_words = _create_documents_per_words(freq_matrix)\n",
    "    idf_matrix = _create_idf_matrix(freq_matrix, documents_per_words, total_documents)\n",
    "    tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    \n",
    "    return tf_idf_matrix\n",
    "\n",
    "# Create word frequency matrix for documents\n",
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    ps = SnowballStemmer(\"english\")\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        dictionary_tokenizer = MWETokenizer(words, separator=' ') \n",
    "        dictionary_based_token = dictionary_tokenizer.tokenize(words) \n",
    "\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "                \n",
    "        # Adding bigrams as phrases\n",
    "        bigrams = list(nltk.bigrams(words))\n",
    "        for bigram in bigrams:\n",
    "            phrase = ' '.join(bigram)\n",
    "            phrase_words = phrase.split(' ')\n",
    "            if all(word not in stopWords for word in phrase_words):\n",
    "                if phrase in freq_table:\n",
    "                    freq_table[phrase] += 1\n",
    "                else:\n",
    "                    freq_table[phrase] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix\n",
    "\n",
    "# Create TF (text frequency) matrix for documents\n",
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix\n",
    "\n",
    "# Find number of documents per words\n",
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table\n",
    "\n",
    "# Create IDF (inverse document frequency) matrix for documents\n",
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            if float(count_doc_per_words[word]) == 0 or total_documents == 0:\n",
    "                idf_table[word] = 0.0\n",
    "            else:\n",
    "                idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix\n",
    "\n",
    "# TF-IDF = TF * IDF matrices\n",
    "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0d95112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_df['actualText'] = ''\n",
    "\n",
    "for index, row in sm_df.iterrows():\n",
    "    if (row['actualText'] == ''):\n",
    "        if (row['translate']) == 'True' :\n",
    "            sm_df.at[index, 'actualText'] = row['text_translated']\n",
    "        else:\n",
    "            sm_df.at[index, 'actualText'] = row['content']\n",
    "\n",
    "# Use weekly-text dataframe to generate TF-IDF matrices\n",
    "# weekly_text = sm_df.groupby([pd.Grouper(key='authoredAt', freq='W')])['actualText'].agg(\n",
    "#     text_combined=' '.join,  # Aggregating text as before\n",
    "#     count='count'  # Adding count aggregation for number of posts\n",
    "# ).reset_index()\n",
    "\n",
    "weekly_text = weekly_text.rename(columns={'authoredAt': 'weekAuthored'})\n",
    "weekly_text = weekly_text.rename(columns={'text_combined': 'textProcessed'})\n",
    "\n",
    "weekly_text['tfIdfMatrix'] = [{} for _ in range(len(weekly_text))]\n",
    "\n",
    "text = weekly_text.at[0, 'textProcessed']\n",
    "count = weekly_text.at[0,'count']\n",
    "\n",
    "for index, row in weekly_text[::-1].iterrows():\n",
    "    text = weekly_text.at[index, 'textProcessed']\n",
    "    count = weekly_text.at[index,'count']\n",
    "    \n",
    "    if row['tfIdfMatrix'] == {}:\n",
    "        matrix = generate_matrix(text, count)\n",
    "        # print(matrix)\n",
    "        \n",
    "        for dictionary in matrix.values():\n",
    "            weekly_text.at[index, 'tfIdfMatrix'] = dictionary\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d9734f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_df.to_pickle('updated_testing_data.pkl')\n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba5ffe8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekAuthored</th>\n",
       "      <th>textProcessed</th>\n",
       "      <th>count</th>\n",
       "      <th>tfIdfMatrix</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-02 00:00:00+00:00</td>\n",
       "      <td>LATEST: At least five people test positive for...</td>\n",
       "      <td>39</td>\n",
       "      <td>{'georgia': 0.19780092313970737, 'covid-19': 0...</td>\n",
       "      <td>[updates, Georgia COVID-19, COVID-19 Updates, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 00:00:00+00:00</td>\n",
       "      <td>â€œHis life should be a testament to us of just ...</td>\n",
       "      <td>247</td>\n",
       "      <td>{'1st': 0.05504386730514959, 'dose': 0.0392001...</td>\n",
       "      <td>[mothersday2021 #, 1st dose, â€œ Hospitals, mass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-16 00:00:00+00:00</td>\n",
       "      <td>Does anyone else experience symptoms of a uti,...</td>\n",
       "      <td>209</td>\n",
       "      <td>{'godbless': 0.07733820953703514, 'start': 0.0...</td>\n",
       "      <td>[godbless, notification, mspears96 That, @ msp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-23 00:00:00+00:00</td>\n",
       "      <td>At last my uncle tested negative he was in the...</td>\n",
       "      <td>221</td>\n",
       "      <td>{'#': 0.11032557167329178, 'believehavefaith':...</td>\n",
       "      <td>[believehavefaith, godisahealer, weightloss, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-30 00:00:00+00:00</td>\n",
       "      <td>Pfizer-BioNTech and Moderna are underway with...</td>\n",
       "      <td>211</td>\n",
       "      <td>{'#': 0.012449963103581173, 'college': 0.02942...</td>\n",
       "      <td>[college, MIRROR SOURCE, FoxNews https, : //ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-06 00:00:00+00:00</td>\n",
       "      <td>Puerto Rico ended a nightly pandemic curfew af...</td>\n",
       "      <td>213</td>\n",
       "      <td>{'https': 0.11004567061101883, ':': 0.08291315...</td>\n",
       "      <td>[//t.co/ly0vx50zka, : //t.co/ly0vx50ZKa, https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-13 00:00:00+00:00</td>\n",
       "      <td>I am asking this question for a friend. My fri...</td>\n",
       "      <td>197</td>\n",
       "      <td>{'hear': 0.19934362304976116, 'comment': 0.199...</td>\n",
       "      <td>[I hear, comment ,, I posted, hear, comment, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-20 00:00:00+00:00</td>\n",
       "      <td>Today was one of those days when everything hu...</td>\n",
       "      <td>245</td>\n",
       "      <td>{'stories': 0.13425123616507406, 'background':...</td>\n",
       "      <td>[//abcn.ws/3iwfsmp, FDA policy, policy :, : //...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-27 00:00:00+00:00</td>\n",
       "      <td>@JennyErikson Contact your insurance provider....</td>\n",
       "      <td>203</td>\n",
       "      <td>{'experiencing': 0.487465999299652, 'doctor': ...</td>\n",
       "      <td>[experiencing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-07-04 00:00:00+00:00</td>\n",
       "      <td>A doctor in Rhode Island faces thousands of do...</td>\n",
       "      <td>206</td>\n",
       "      <td>{'gente': 0.01131475413383449, 'por': 0.009131...</td>\n",
       "      <td>[como, humana, escencia, pero, nuestra escenci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               weekAuthored  \\\n",
       "0 2021-05-02 00:00:00+00:00   \n",
       "1 2021-05-09 00:00:00+00:00   \n",
       "2 2021-05-16 00:00:00+00:00   \n",
       "3 2021-05-23 00:00:00+00:00   \n",
       "4 2021-05-30 00:00:00+00:00   \n",
       "5 2021-06-06 00:00:00+00:00   \n",
       "6 2021-06-13 00:00:00+00:00   \n",
       "7 2021-06-20 00:00:00+00:00   \n",
       "8 2021-06-27 00:00:00+00:00   \n",
       "9 2021-07-04 00:00:00+00:00   \n",
       "\n",
       "                                       textProcessed  count  \\\n",
       "0  LATEST: At least five people test positive for...     39   \n",
       "1  â€œHis life should be a testament to us of just ...    247   \n",
       "2  Does anyone else experience symptoms of a uti,...    209   \n",
       "3  At last my uncle tested negative he was in the...    221   \n",
       "4   Pfizer-BioNTech and Moderna are underway with...    211   \n",
       "5  Puerto Rico ended a nightly pandemic curfew af...    213   \n",
       "6  I am asking this question for a friend. My fri...    197   \n",
       "7  Today was one of those days when everything hu...    245   \n",
       "8  @JennyErikson Contact your insurance provider....    203   \n",
       "9  A doctor in Rhode Island faces thousands of do...    206   \n",
       "\n",
       "                                         tfIdfMatrix  \\\n",
       "0  {'georgia': 0.19780092313970737, 'covid-19': 0...   \n",
       "1  {'1st': 0.05504386730514959, 'dose': 0.0392001...   \n",
       "2  {'godbless': 0.07733820953703514, 'start': 0.0...   \n",
       "3  {'#': 0.11032557167329178, 'believehavefaith':...   \n",
       "4  {'#': 0.012449963103581173, 'college': 0.02942...   \n",
       "5  {'https': 0.11004567061101883, ':': 0.08291315...   \n",
       "6  {'hear': 0.19934362304976116, 'comment': 0.199...   \n",
       "7  {'stories': 0.13425123616507406, 'background':...   \n",
       "8  {'experiencing': 0.487465999299652, 'doctor': ...   \n",
       "9  {'gente': 0.01131475413383449, 'por': 0.009131...   \n",
       "\n",
       "                                              values  \n",
       "0  [updates, Georgia COVID-19, COVID-19 Updates, ...  \n",
       "1  [mothersday2021 #, 1st dose, â€œ Hospitals, mass...  \n",
       "2  [godbless, notification, mspears96 That, @ msp...  \n",
       "3  [believehavefaith, godisahealer, weightloss, t...  \n",
       "4  [college, MIRROR SOURCE, FoxNews https, : //ww...  \n",
       "5  [//t.co/ly0vx50zka, : //t.co/ly0vx50ZKa, https...  \n",
       "6  [I hear, comment ,, I posted, hear, comment, I...  \n",
       "7  [//abcn.ws/3iwfsmp, FDA policy, policy :, : //...  \n",
       "8                                     [experiencing]  \n",
       "9  [como, humana, escencia, pero, nuestra escenci...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_df = pd.read_pickle('weekly_tf_idf.pkl')\n",
    "weekly_df['values'] = [[] for _ in range(len(weekly_text))]\n",
    "more_stopwords = [\n",
    "    'covid',\n",
    "    'coronavirus',\n",
    "    'corona',\n",
    "    'rona',\n",
    "    'covid-19',\n",
    "    'tested',\n",
    "    'testing',\n",
    "    'test',\n",
    "    'tests',\n",
    "    'symptoms',\n",
    "    'positive',\n",
    "    'negative',\n",
    "    'para',\n",
    "    'vaccine',\n",
    "    'vaccines',\n",
    "    'vaccinated',\n",
    "    'virus'\n",
    "    'tests',\n",
    "    'people',\n",
    "    'health',\n",
    "    'pandemic',\n",
    "    'virus',\n",
    "    'sars-cov-2',\n",
    "    'doctor',\n",
    "    'covid19',\n",
    "    'vaccination',\n",
    "    'vaccinations',\n",
    "    'rt @',\n",
    "    '-- --',\n",
    "    '',\n",
    "    \"I'm\", \n",
    "    r'\\u']\n",
    "    \n",
    "# filtered_list = list(set(sorted_dict).difference(stopwords))\n",
    "    \n",
    "for index, row in weekly_df.iterrows():\n",
    "    # Remove one-character words or strange numbers..\n",
    "    items = row['tfIdfMatrix'].items()\n",
    "    matrix_modified = {}\n",
    "    for key, value in items:  \n",
    "        if not key.isdigit() and len(key) > 3:\n",
    "            # Remove stopwords\n",
    "            words = key.split()\n",
    "            if all(word not in more_stopwords for word in words):\n",
    "                matrix_modified[key] = value\n",
    "\n",
    "    weekly_df.at[index, 'tfIdfMatrix'] = matrix_modified\n",
    "\n",
    "    sorted_df = pd.DataFrame.from_dict(matrix_modified, orient='index', columns=['tfIdfValue'])\n",
    "    sorted_df = sorted_df.reset_index()\n",
    "    sorted_df = sorted_df.rename(columns={'index' : 'keyword'})\n",
    "    sorted_df = sorted_df.sort_values(by='tfIdfValue', ascending=False)\n",
    "    sorted_dict = sorted_df['keyword'].tolist()\n",
    "    \n",
    "    for item in more_stopwords:\n",
    "        if item in sorted_dict:\n",
    "            sorted_dict.remove(item)\n",
    "    \n",
    "    sorted_dict = [item for item in sorted_dict if item]\n",
    "    \n",
    "    sorted_dict = sorted_dict[:20] # keep only the first 20 values\n",
    "    # print(sorted_dict)\n",
    "    weekly_text.at[index, 'values'] = sorted_dict\n",
    "    \n",
    "weekly_text.to_pickle('weekly_tf_idf.pkl')\n",
    "\n",
    "weekly_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7fe3151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survivor Corps',\n",
       " 'Hispanic Health Coalition of Georgia, Inc',\n",
       " 'Stand for Health Freedom',\n",
       " 'A Voice for Choice',\n",
       " 'COVID-19 Novel Coronavirus FACTS',\n",
       " 'Fulton County Board of Health',\n",
       " 'Â¡MÃ‰DICOS POR LA VERDAD!',\n",
       " 'COVID-19 Long Haulers Support',\n",
       " 'U.S. Department of Health and Human Services',\n",
       " \"Skip Mason's Vanishing Black Atlanta History\",\n",
       " 'CDC',\n",
       " 'MedLink Georgia',\n",
       " 'News Medical',\n",
       " 'WebMD',\n",
       " 'Georgia Family Planning System',\n",
       " 'The Prayer Wall',\n",
       " '41NBC / WMGT',\n",
       " 'FOX 5 Atlanta',\n",
       " 'MedCura Health',\n",
       " 'ABC News',\n",
       " 'Black Educators',\n",
       " 'Doctor Mike',\n",
       " 'Clark Atlanta University',\n",
       " 'Southwest Georgia Public Health District',\n",
       " 'Georgia Coalition for Vaccine Choice',\n",
       " 'GNR Public Health',\n",
       " 'Clila- CoaliciÃ³n De LÃ­deres Latinos',\n",
       " 'Georgia Department of Public Health',\n",
       " 'KISS 104.1',\n",
       " 'Phoebe Putney Health System',\n",
       " 'Gayle King',\n",
       " 'Verywell',\n",
       " 'Vaccines save lives',\n",
       " 'El Profe Perulero Radio',\n",
       " 'VICE',\n",
       " 'Prensa Atlanta',\n",
       " 'Fair Count',\n",
       " 'Breitbart',\n",
       " 'Covid Wellness Clinic',\n",
       " 'Medical News Today',\n",
       " 'Healthcare Insider',\n",
       " 'Univision 34 Atlanta',\n",
       " 'FOX 31 WFXL-TV ALBANY',\n",
       " 'Fulton County Government',\n",
       " 'Georgia CEAL',\n",
       " 'DeKalb County, GA Board of Health',\n",
       " 'America First Tea Party',\n",
       " 'POPSUGAR Wellness',\n",
       " 'Polk County Standard Journal',\n",
       " '11Alive',\n",
       " 'Barrow County Health Department',\n",
       " 'Health',\n",
       " 'News 12 NBC 26',\n",
       " 'BlackDoctor.org',\n",
       " 'AARP',\n",
       " 'GPB News',\n",
       " 'Prevention Magazine',\n",
       " '13 WMAZ',\n",
       " 'Well+Good',\n",
       " 'BlackAmericaWeb.com',\n",
       " 'Clayton County Government',\n",
       " 'Atlanta News First',\n",
       " 'BuzzFeed Health',\n",
       " 'Congressman David Scott',\n",
       " 'Ledger-Enquirer',\n",
       " 'State Representative Rhonda Burnough',\n",
       " 'Atlanta-Fulton County Emergency Management Agency (AFCEMA)',\n",
       " 'Complex News',\n",
       " 'HISPATLANTA',\n",
       " 'Latino Community Fund -LCF Georgia',\n",
       " 'Athens GA COVID-19 Resources and Discussion',\n",
       " 'All On Georgia - Chattooga',\n",
       " 'Everyday Health',\n",
       " 'Medical Daily',\n",
       " 'Melissa Harris-Perry',\n",
       " 'TheGrio',\n",
       " 'NotiVisiÃ³n Georgia',\n",
       " 'Kaiser Health News',\n",
       " 'Type2Diabetes.com',\n",
       " 'VIBE',\n",
       " 'Georgia Public Broadcasting',\n",
       " '95.5 WSB',\n",
       " 'SELF',\n",
       " 'CBS News',\n",
       " 'Univision Noticias',\n",
       " 'Noticias Telemundo',\n",
       " 'CNN',\n",
       " 'CNN en EspaÃ±ol',\n",
       " 'Dalton Daily Citizen',\n",
       " 'HuffPost Black Voices',\n",
       " 'Fox News',\n",
       " 'Clayton County Health District',\n",
       " 'LiveScience',\n",
       " 'NPR',\n",
       " 'Caracol TelevisiÃ³n',\n",
       " 'The Atlanta Journal-Constitution',\n",
       " 'Atlanta Business Chronicle',\n",
       " 'VICE News',\n",
       " 'Cleveland Clinic',\n",
       " 'TERMINÃ“ ðŸ§‘\\u200dðŸ¦½ðŸ§‘\\u200dðŸ¦½ðŸ§‘\\u200dðŸ¦½ðŸ§‘\\u200dðŸ¦½',\n",
       " \"Men's Health\",\n",
       " 'Dank Diabetes Memes Diabuddies',\n",
       " 'Atlanta Black Star',\n",
       " 'southhealthdistrict',\n",
       " 'coastalhealth91',\n",
       " 'unbiasedscipod',\n",
       " 'northgahealth',\n",
       " 'wearebreitbart',\n",
       " 'nihgov',\n",
       " 'clila.coalicion.lideres.latino',\n",
       " 'abcnews',\n",
       " 'sybilwilkes',\n",
       " 'hispanichealth',\n",
       " 'bcagainstcovid',\n",
       " 'npr',\n",
       " 'minorityhealth',\n",
       " 'webmd',\n",
       " 'noticiascaracol',\n",
       " 'georgia_ceal',\n",
       " 'kaiserhealthnews',\n",
       " 'newscientist',\n",
       " 'fultonhealth',\n",
       " 'cnbc',\n",
       " 'vicenews',\n",
       " 'nationalcancerinstitute',\n",
       " 'cdcgov',\n",
       " 'cheddar',\n",
       " 'd4publichealth',\n",
       " 'selfmagazine',\n",
       " 'health',\n",
       " 'buzzfeednews',\n",
       " 'coreresponse',\n",
       " 'medlinkga',\n",
       " 'planfirstga',\n",
       " 'dr_shaps',\n",
       " 'medcurahealth',\n",
       " 'sehdph',\n",
       " 'healthline',\n",
       " 'epochtimes',\n",
       " 'cnnee',\n",
       " 'cbseveningnews',\n",
       " 'fultoninfo',\n",
       " 'lcac.news',\n",
       " 'drsupremeunderstanding',\n",
       " 'afro.tech',\n",
       " 'swhd82',\n",
       " 'healthydekalb',\n",
       " 'eastcentralhealth',\n",
       " 'axios',\n",
       " 'wsbradio',\n",
       " 'cbsnews',\n",
       " 'cnnpolitics',\n",
       " 'theshaderoom',\n",
       " 'hoodratchetv',\n",
       " 'hispatlanta',\n",
       " 'georgiadph',\n",
       " 'cdphga',\n",
       " 'ajcnews',\n",
       " 'TelemundoNews',\n",
       " 'hood_medicine',\n",
       " 'CNNEE',\n",
       " 'HhcgaT',\n",
       " 'BCAgainstCOVID',\n",
       " 'GEORGIA_CEAL',\n",
       " 'CDCgov',\n",
       " 'PublicHealth',\n",
       " 'EmoryRollins',\n",
       " 'Hardrick_Willis',\n",
       " 'KelleyKga',\n",
       " 'HighWireTalk',\n",
       " 'ChildrensHD',\n",
       " 'NickHudsonCT',\n",
       " 'EpochTimes',\n",
       " 'PanData19',\n",
       " 'ICANdecide',\n",
       " 'lifebiomedguru',\n",
       " 'RobertKennedyJr',\n",
       " 'backtolife_2023',\n",
       " 'rondeaulivia',\n",
       " 'drsimonegold',\n",
       " 'picphysicians',\n",
       " 'gummibear737',\n",
       " 'unhealthytruth',\n",
       " 'Covid19Critical',\n",
       " 'oni_blackstock',\n",
       " 'long_covid',\n",
       " 'GaCharityCare',\n",
       " 'dianaberrent',\n",
       " 'SouthHealthDist',\n",
       " 'CarlosdelRio7',\n",
       " 'NGAHealthDist',\n",
       " 'MelDMann',\n",
       " 'HHSGov',\n",
       " 'ClaytonCountyHD',\n",
       " 'AmerMedicalAssn',\n",
       " 'FultonHealth',\n",
       " 'NPRHealth',\n",
       " 'NBCNewsHealth',\n",
       " 'CommAPSProgress',\n",
       " 'TheHenryHerald',\n",
       " 'wabenews',\n",
       " 'staceyhopkinsga',\n",
       " 'cobblibrary',\n",
       " 'RockdaleSchools',\n",
       " 'FOX5Atlanta',\n",
       " 'CityofAtlanta',\n",
       " 'WALBNews10',\n",
       " 'FultonInfo',\n",
       " 'CBSNews',\n",
       " 'ABC',\n",
       " '11AliveNews',\n",
       " 'ajc',\n",
       " 'FoxNews',\n",
       " 'blackvoices',\n",
       " 'NIH',\n",
       " 'autismhav3r',\n",
       " 'JadeLove21__',\n",
       " 'dangerwoman23',\n",
       " 'drsajumathew',\n",
       " 'Coronavirus Updates for: Statesboro, Georgia & Surrounding Counties',\n",
       " 'Blavity',\n",
       " 'Amber Schmidtke, PhD',\n",
       " 'Mayor Van Johnson',\n",
       " 'COVID19: Real Talk from Health Care Workers around the Globe',\n",
       " 'Noticias para Inmigrantes',\n",
       " 'Consulado General de MÃ©xico en Atlanta',\n",
       " 'Forsyth County News',\n",
       " 'Essence',\n",
       " 'CORE Georgia',\n",
       " 'Albany Area Primary Health Care, Inc.',\n",
       " 'EBONY',\n",
       " 'The New York Times - Well - Health',\n",
       " 'Rome News-Tribune',\n",
       " 'Catoosa Walker News',\n",
       " \"Men's Journal\",\n",
       " 'Black News Network (BNN)',\n",
       " \"Dar'shun Nicole Kendrick\",\n",
       " 'April D Ryan',\n",
       " 'Cumming Patch',\n",
       " 'The Georgia Star News',\n",
       " 'First Baptist Church Atlanta',\n",
       " 'Representative Kim Schofield',\n",
       " 'Amala Ekpunobi',\n",
       " 'Morehouse School of Medicine',\n",
       " 'Georgia Chapter of the American Academy of Pediatrics',\n",
       " 'NIH News in Health',\n",
       " 'Dr. Joseph Mercola',\n",
       " 'Fitzgerald Herald-Leader',\n",
       " 'Savannah Morning News & SavannahNow.com',\n",
       " 'Midtown Atlanta Patch',\n",
       " 'Afro-American Newspapers',\n",
       " 'The Family Health Centers of Georgia, Inc.',\n",
       " 'Diabetes Self-Management',\n",
       " 'DeKalb Strong',\n",
       " 'Transamerica Institute',\n",
       " 'Mercy Care',\n",
       " '94.9 The Bull',\n",
       " 'Calhoun Times',\n",
       " 'North Druid Hills-Briarcliff Patch',\n",
       " 'Norcross Patch',\n",
       " 'Georgia Trump Republicans',\n",
       " 'Marietta, GA Patch',\n",
       " 'mindbodygreen',\n",
       " 'Noticias Georgia',\n",
       " 'Cherokee Tribune & Ledger-News',\n",
       " 'JDRF',\n",
       " 'vactruth.com',\n",
       " 'WRFG 89.3 FM',\n",
       " \"Women's Health\",\n",
       " 'Atlanta Daily World',\n",
       " 'Marietta Daily Journal',\n",
       " 'Connect Savannah',\n",
       " 'Our Black Union',\n",
       " 'Organic Consumers Association',\n",
       " 'The Root',\n",
       " 'Georgia Voice',\n",
       " 'NBC News Health',\n",
       " 'Lester Holt',\n",
       " 'Candace Owens',\n",
       " 'La Raza Atlanta',\n",
       " 'Georgia State University',\n",
       " 'Creative Loafing Atlanta',\n",
       " 'Albany Herald',\n",
       " 'Southside Medical Center',\n",
       " 'Smyrna-Vinings Patch',\n",
       " 'Mundo HispÃ¡nico Atlanta',\n",
       " 'Gainesville Times',\n",
       " 'Coosa Valley News',\n",
       " 'COVID-19 Watch North GA w/ Help & Resources',\n",
       " 'MundoNow',\n",
       " 'Lake Oconee News',\n",
       " 'Dr. Mehmet Oz',\n",
       " 'All On Georgia - Evans',\n",
       " 'Americus Times-Recorder',\n",
       " 'Georgia Department of Community Health',\n",
       " 'Star 94 Atlanta',\n",
       " 'Athens Banner-Herald & OnlineAthens.com',\n",
       " 'Charles Payne',\n",
       " 'Rockdale County Government',\n",
       " 'Gwinnett Daily Post',\n",
       " 'Georgia Primary Care Association',\n",
       " 'Covington News',\n",
       " 'All On Georgia - Floyd',\n",
       " 'Atlanta Magazine',\n",
       " 'Clinch County News',\n",
       " 'Flagpole Magazine',\n",
       " 'Representative Dr. Jasmine Clark',\n",
       " \"Children's Healthcare of Atlanta\",\n",
       " 'Fulton County Schools',\n",
       " 'Cartersville Daily Tribune',\n",
       " 'Joy Reid',\n",
       " 'Black Knowledge',\n",
       " 'Politically Georgia',\n",
       " 'Congressman Hank Johnson',\n",
       " 'Franklin County Citizen Leader',\n",
       " 'All On Georgia - Bulloch',\n",
       " 'Atlanta Humane Society',\n",
       " 'Coastal Courier',\n",
       " 'Congressman Barry Loudermilk',\n",
       " 'Atlanta Public Schools',\n",
       " 'The City of Albany',\n",
       " 'Fetch Your News',\n",
       " 'Morgan County Citizen',\n",
       " 'Candace',\n",
       " 'Tabernacle Atlanta',\n",
       " 'Michael J Bond',\n",
       " 'Georgia on my mind',\n",
       " '21 Ninety',\n",
       " 'Clayton News',\n",
       " 'Atlanta Housing',\n",
       " 'City of Atlanta Government',\n",
       " 'King Cam',\n",
       " 'Steven Crowder',\n",
       " 'SHAPE',\n",
       " 'Bezzy Type 2 Diabetes',\n",
       " 'Dawson County News',\n",
       " 'The Hip Hop Doc - Dr. MJ Collier',\n",
       " 'Georgia Council on Developmental Disabilities',\n",
       " 'Andrew J. Young Foundation',\n",
       " 'Andre Dickens',\n",
       " 'Savannah State University',\n",
       " 'Diabetes Daily',\n",
       " 'Elizabeth Baptist Church',\n",
       " 'Wes Moore',\n",
       " 'Bishop Oliver Clyde Allen, III',\n",
       " 'Vision Cathedral ATL',\n",
       " 'The United Progressive Pentecostal Church',\n",
       " 'Henry Herald',\n",
       " 'GradyHealth',\n",
       " 'City of Atlanta Police Department',\n",
       " 'Craig Melvin',\n",
       " 'Clayton County Police Department',\n",
       " 'Frontline Response',\n",
       " 'State Representative CaMia Jackson - HD 153',\n",
       " 'Dunwoody Crier',\n",
       " 'William K. Boddie Jr.',\n",
       " 'State Representative Renitta Shannon',\n",
       " 'Mayor Booker T. Gainor',\n",
       " 'Bryan County News',\n",
       " 'Georgia Department of Human Services',\n",
       " 'Houston Home Journal',\n",
       " 'All On Georgia - Glynn',\n",
       " 'Rep. Lucy McBath',\n",
       " 'HBCU Buzz',\n",
       " 'Albany, GA Area Happenings Over 21',\n",
       " 'Beulah Missionary Baptist Church',\n",
       " 'Diabetes Research Institute Foundation',\n",
       " 'All On Georgia.com',\n",
       " 'Kimono My House (Virtual House Concerts)',\n",
       " 'Type 1 Diabetes Recipes & Food Ideas',\n",
       " 'Robert F. Kennedy, Jr',\n",
       " 'Access Atlanta',\n",
       " 'Beyond Type 1',\n",
       " 'Atlanta Community Food Bank',\n",
       " 'Carolyn Hugley',\n",
       " 'Forest Park Mayor Angelyne Butler, MPA',\n",
       " 'HBCU CONNECT',\n",
       " 'Charlton County Herald',\n",
       " 'atlhawks',\n",
       " 'aarp',\n",
       " 'niniandthebrain',\n",
       " 'ircatlanta',\n",
       " 'buzzfeed',\n",
       " 'enews',\n",
       " 'lcf_georgia',\n",
       " 'streetz945atl',\n",
       " 'cnn',\n",
       " 'wellstarhealth',\n",
       " 'who',\n",
       " 'deptvetaffairs',\n",
       " 'emoryhealthcare',\n",
       " 'unitedwayatlanta',\n",
       " 'marioguevaranews',\n",
       " 'epochtimeses',\n",
       " 'morehouseschoolofmedicine',\n",
       " 'ajplus',\n",
       " 'morehouse1867',\n",
       " 'alrojovivo',\n",
       " 'despiertamerica',\n",
       " 'core_georgia',\n",
       " 'blkwomenshealth',\n",
       " 'forsythnews',\n",
       " 'drgarthdavis',\n",
       " 'glblctzn',\n",
       " 'sghscares',\n",
       " 'ihooptoo',\n",
       " 'msbasketball1',\n",
       " 'mediawise',\n",
       " 'ugavaccine',\n",
       " 'byrdie',\n",
       " 'preventionmag',\n",
       " 'scientific_american',\n",
       " 'v103atlanta',\n",
       " 'walbnews10',\n",
       " 'dekalbschools',\n",
       " 'aliveandincolor',\n",
       " 'chris180_advocate',\n",
       " 'jerrynews',\n",
       " 'bncnews',\n",
       " 'afropunk',\n",
       " 'creativeloafingatlanta',\n",
       " 'brotherkingcam',\n",
       " 'blackhammertimes',\n",
       " 'russellbrand',\n",
       " 'thegrio',\n",
       " 'complexnews',\n",
       " 'onlineathens_com',\n",
       " 'bigtiggermorningshow',\n",
       " '1380waok',\n",
       " 'phoebehealth',\n",
       " 'abcworldnewstonight',\n",
       " 'cbsmornings',\n",
       " 'andalequeesperas',\n",
       " 'realcandaceowens',\n",
       " 'drsanjaygupta',\n",
       " 'thecourierherald',\n",
       " 'thenortheastgeorgian',\n",
       " '11alive',\n",
       " 'atlscoop',\n",
       " 'georgiastateuniversity',\n",
       " 'savannahnow',\n",
       " 'thecovenantatl',\n",
       " 'southsidemedical',\n",
       " 'complex',\n",
       " 'verywellmind',\n",
       " 'atlantadailyworld',\n",
       " 'cbssundaymorning',\n",
       " 'salembiblechurch',\n",
       " 'savannahstate',\n",
       " 'dreamcenteratl',\n",
       " 'ulga_yp',\n",
       " 'world',\n",
       " 'statnews',\n",
       " 'fox5atlanta',\n",
       " 'ledgerenquirer',\n",
       " 'womenshealthmag',\n",
       " 'vacunate_ya',\n",
       " 'butter.atl',\n",
       " 'crookedmedia',\n",
       " 'doctor.darien',\n",
       " 'clevelandclinic',\n",
       " 'blavity',\n",
       " 'atlantanewsfirst',\n",
       " 'sciencemagazine',\n",
       " 'ebcinyourcity',\n",
       " 'u.s.surgeongeneral',\n",
       " 'eateratlanta',\n",
       " 'vabenefits',\n",
       " 'atlanta_meme',\n",
       " 'hohatl',\n",
       " 'edeweysmith',\n",
       " 'everydayhealth',\n",
       " 'hbcualum',\n",
       " 'askdrmj',\n",
       " 'gradyhealth',\n",
       " 'hivgov',\n",
       " 'usedgov',\n",
       " 'hbcubuzz',\n",
       " 'iamwellandgood',\n",
       " 'the_savannahtribune',\n",
       " 'mercycareatlanta',\n",
       " 'fhcga',\n",
       " 'supremeunderstanding',\n",
       " 'BadCOVID19Takes',\n",
       " 'GaDPH',\n",
       " 'Survivor_Corps',\n",
       " 'act_covid',\n",
       " 'TheRSMS',\n",
       " 'HealthyDeKalb',\n",
       " 'gsuprc',\n",
       " 'GSU_Research',\n",
       " 'ProParentRights',\n",
       " 'UNICEF',\n",
       " 'CDPHga',\n",
       " 'AJCsports',\n",
       " 'JohnsHopkinsSPH',\n",
       " 'V2019N',\n",
       " 'blkhlth',\n",
       " 'EmoryDeptofMed',\n",
       " 'GwinnettNewsNow',\n",
       " 'ATLNewsFirst',\n",
       " 'WHO',\n",
       " 'marclamonthill',\n",
       " 'Joy105com',\n",
       " 'ebenezer_atl',\n",
       " 'ATLGAUSA',\n",
       " 'rolandsmartin',\n",
       " 'MarkArum',\n",
       " 'CoreResponse',\n",
       " 'ASlavitt',\n",
       " 'JoyAnnReid',\n",
       " 'delbigtree',\n",
       " 'emoryhealthsci',\n",
       " 'theatlantavoice',\n",
       " 'hot1079atl',\n",
       " 'AtlNewsNow',\n",
       " 'NCHD52',\n",
       " 'cynthiamckinney',\n",
       " 'GAVaccineChoice',\n",
       " 'MSMEDU',\n",
       " 'SenatorWarnock',\n",
       " 'unitedwayatl',\n",
       " 'teensforvaxx',\n",
       " 'covidtweets',\n",
       " 'wsbtv',\n",
       " 'GovKemp',\n",
       " 'DavidHollandMD',\n",
       " 'CovidFinishLine',\n",
       " 'BlkHmmrTimes',\n",
       " 'NBCLatino',\n",
       " 'MayaTPrabhu',\n",
       " 'FacesOfCOVID',\n",
       " 'AtlantaNewsFeed',\n",
       " 'gpbnews',\n",
       " 'GwinnettDaily',\n",
       " 'NationalMedAssn',\n",
       " 'bluestein',\n",
       " 'Albany_Herald',\n",
       " 'D4publichealth',\n",
       " 'DecaturGAPatch',\n",
       " 'greaterthanCV19',\n",
       " 'bennyjohnson',\n",
       " 'DrJayneMorgan',\n",
       " 'rockdalecitizen',\n",
       " 'ThisIsOurShot',\n",
       " 'akasorority1908',\n",
       " 'gradydoctor',\n",
       " 'mercola',\n",
       " 'ManageDiabetes',\n",
       " 'Cleavon_MD',\n",
       " 'mercyatlanta',\n",
       " 'DrButtar',\n",
       " 'EAtlantaPatch',\n",
       " 'WhitlockJason',\n",
       " 'WhyWeVax',\n",
       " 'EmoryMedicine',\n",
       " 'BCSchools1',\n",
       " 'EastCobbPatch',\n",
       " 'MsLaToshaBrown',\n",
       " 'childrensatl',\n",
       " 'ClaytonCountyGA',\n",
       " 'ClaytonTV23',\n",
       " 'scoreatlanta',\n",
       " 'gatewayctr',\n",
       " 'AFCEMA',\n",
       " 'GeorgiaStateU',\n",
       " 'downtownatlanta',\n",
       " 'iMajorWish',\n",
       " 'FGTV',\n",
       " 'CobbChamber',\n",
       " 'cobbcountygovt',\n",
       " 'mdjonline',\n",
       " 'BreeNewsome',\n",
       " 'SouthCobbPatch',\n",
       " 'Not_the_Bee',\n",
       " 'tariqnasheed',\n",
       " 'theGrio',\n",
       " 'larryfeltonj',\n",
       " 'Maria_Hinojosa',\n",
       " 'MelechThomas',\n",
       " 'jewelwickershow',\n",
       " 'TheRoot',\n",
       " 'TheBabylonBee',\n",
       " 'EBONYMag',\n",
       " 'NBCBLK',\n",
       " 'GAFollowers',\n",
       " 'ProudoftheUSA',\n",
       " 'RepMTG',\n",
       " 'RealCandaceO',\n",
       " 'TheWayWithAnoa',\n",
       " 'DeKalbSchools',\n",
       " 'COVID_19Network',\n",
       " 'DoctorDarienMD',\n",
       " 'WFXL',\n",
       " 'GwinnettDems',\n",
       " 'DeKalbCountyPD',\n",
       " 'blackdoctorsusa',\n",
       " 'itsbodypolitic',\n",
       " 'michaelharriot',\n",
       " 'georgiayouthco',\n",
       " 'WHCOVIDResponse',\n",
       " 'EbcInYourCity',\n",
       " 'shulermom',\n",
       " 'donnalowrynews',\n",
       " 'GAChapterAAP',\n",
       " 'tanulewicz',\n",
       " 'DrIbram',\n",
       " 'praise1025',\n",
       " 'georgiastateSC',\n",
       " 'karlaWALB',\n",
       " 'CAU',\n",
       " 'ChristineOnTV',\n",
       " 'SmyrnaPatch',\n",
       " 'georgiawatch',\n",
       " 'CCPSNews',\n",
       " 'CobbCountyTV',\n",
       " 'BrookhavenGaGov',\n",
       " 'WhatIsAtlanta',\n",
       " 'blackenterprise',\n",
       " 'FCSSuptLooney',\n",
       " 'Latinovations',\n",
       " 'Phoebe_Putney',\n",
       " 'WellstarHealth',\n",
       " 'KasimReed',\n",
       " 'donnabrazile',\n",
       " 'AudreyWSBTV',\n",
       " 'FHCGA_',\n",
       " 'DeKalbCountyEMA',\n",
       " 'UWGA211',\n",
       " 'HealthyFutureGA',\n",
       " 'CobbCourier',\n",
       " 'Morehouse',\n",
       " 'RockdaleGov',\n",
       " 'cityofsavannah',\n",
       " 'ATL_Events',\n",
       " 'WeAreUnidosUS',\n",
       " 'CobbCountyGIS',\n",
       " 'MauraSirianni',\n",
       " 'NextGenAmerica',\n",
       " 'AtlantaMagazine',\n",
       " 'faircount',\n",
       " 'HispanicCaucus',\n",
       " 'VernonForGA',\n",
       " 'GeorgiaVoices',\n",
       " 'NeighborNews',\n",
       " 'JasmineForHD108',\n",
       " 'FultonCoSchools',\n",
       " 'AttorneyGriggs',\n",
       " 'TheKingCenter',\n",
       " 'WAOK',\n",
       " 'GoodDayAtlanta',\n",
       " 'RockdaleEMA',\n",
       " 'ItsInDeKalb',\n",
       " 'rahulbali',\n",
       " 'AliveAndInColor',\n",
       " 'ATLIntownPaper',\n",
       " 'BishopPMorton',\n",
       " 'ravenscimaven',\n",
       " 'LEADDeKalb',\n",
       " 'apsupdate',\n",
       " 'TheClaytonNews',\n",
       " 'Andalequeespera',\n",
       " 'hannahcrileyy',\n",
       " 'NALEO',\n",
       " 'univision34ATL',\n",
       " 'POTUS',\n",
       " 'CalhounTimes',\n",
       " 'AlbanyStateUniv',\n",
       " 'KamalaHarris',\n",
       " 'NVisionMarketin',\n",
       " 'MichaelBJordan',\n",
       " '1047TheFish',\n",
       " 'GSUArtSci',\n",
       " 'DouglasVilPatch',\n",
       " 'GeorgiaRecorder',\n",
       " 'majicatl',\n",
       " 'High5Sports',\n",
       " 'TiaaBrown_',\n",
       " 'SpelmanCollege',\n",
       " 'UnionCityGov',\n",
       " 'SaportaReport',\n",
       " 'LcacNews',\n",
       " 'COSFGA',\n",
       " 'GwinnettSO',\n",
       " 'NAACP_LDF',\n",
       " 'Surgeon_General',\n",
       " 'CHANGINGAGENATL',\n",
       " 'blackintheempir',\n",
       " 'gsu_news',\n",
       " 'TheLAA',\n",
       " 'collinsforkids',\n",
       " 'OattsTerry',\n",
       " 'VaxCalc',\n",
       " 'IamKingWilliams',\n",
       " 'RickeySmiley',\n",
       " 'JeffereyJaxen',\n",
       " 'WelcomingATL',\n",
       " 'keithwhitney',\n",
       " 'atlcouncil',\n",
       " 'HousingAtlanta',\n",
       " 'FultonComm5',\n",
       " 'American_Heart',\n",
       " 'LatinoVoices',\n",
       " 'prceal',\n",
       " 'NoiseFilterShow',\n",
       " 'ShemekaMichelle',\n",
       " 'andreforatlanta',\n",
       " 'ATLHawks',\n",
       " 'gahealthnews',\n",
       " 'GwinnettGov',\n",
       " 'kevdjenkins1',\n",
       " 'covidlatino',\n",
       " 'ErinKPeterson',\n",
       " 'WilNobles',\n",
       " 'HOHATL',\n",
       " 'jfradioshow',\n",
       " 'DougShip',\n",
       " 'ATLUncensored',\n",
       " 'EastCentralPH',\n",
       " 'SenOssoff',\n",
       " 'ossoff',\n",
       " 'Cannonfor58',\n",
       " 'Michael_J_Bond',\n",
       " 'CHRIS180_Change',\n",
       " 'CobbSheriff',\n",
       " 'HoodHealer',\n",
       " 'CobbNewsNow',\n",
       " 'AtlantaInMotion',\n",
       " 'TharonJohnson',\n",
       " 'SunBelt',\n",
       " 'GaRepublicans',\n",
       " 'repdavidscott',\n",
       " 'ChrisJoseTV',\n",
       " 'karyngreer',\n",
       " 'RevDrBarber',\n",
       " 'MayorJohnsonSAV',\n",
       " 'James_Reese_Jr',\n",
       " 'GeorgiaDemocrat',\n",
       " 'DarshunKendrick',\n",
       " 'claytongalib',\n",
       " 'alexisnews',\n",
       " 'archi_atlanta',\n",
       " 'HealthcareGA',\n",
       " 'urbanclinicatl',\n",
       " 'boddieforga',\n",
       " 'themacatlanta',\n",
       " 'ReverendWarnock',\n",
       " 'GASenateDems',\n",
       " 'rowel70',\n",
       " 'GADHS',\n",
       " 'BDTSpelman',\n",
       " 'PiedmontHealth',\n",
       " 'CollegePark_Ga',\n",
       " 'V103Atlanta',\n",
       " 'tedterry1',\n",
       " 'ChairRobbPitts',\n",
       " 'RepHankJohnson',\n",
       " 'gacities',\n",
       " 'SmyrnaNews',\n",
       " 'JonesboroGovt',\n",
       " 'AllofUsResearch',\n",
       " 'VacunateYa',\n",
       " 'GeorgiaStarNews',\n",
       " 'VP',\n",
       " 'GADeptEarlyCare',\n",
       " 'CovidActNow',\n",
       " 'MundoNowOficial',\n",
       " 'quinnmusic',\n",
       " 'DrChrisNorthrup',\n",
       " 'upscalemagazine',\n",
       " 'KillerMike',\n",
       " 'LatinoUSA',\n",
       " 'ATLSAHM',\n",
       " 'GaPlanFirst',\n",
       " 'Brotherkingcam',\n",
       " 'staceyabrams',\n",
       " 'KeishaBottoms',\n",
       " 'sayerjigmi',\n",
       " 'TuckerCarlson',\n",
       " 'sofulliving',\n",
       " 'GaSouthernGuy',\n",
       " 'Rebecca4Georgia',\n",
       " 'wakeupfromcovid',\n",
       " 'mtgreenee',\n",
       " 'SCHD_5_1',\n",
       " 'LaniGrayer',\n",
       " 'jayxlionesss',\n",
       " 'st33bles',\n",
       " 'DavidLengling',\n",
       " 'adiosbeaches',\n",
       " 'DonKramerATL',\n",
       " 'ShibaRussell',\n",
       " 'justcallme_sed',\n",
       " 'johnny_8730',\n",
       " 'SabSilv',\n",
       " 'evesbyu2',\n",
       " 'arlenec90',\n",
       " 'Eli_Major_Mom',\n",
       " 'SashaEats',\n",
       " 'oopsie_daisy4',\n",
       " 'America1stYinz',\n",
       " 'AndreaPowe',\n",
       " 'KPOOKDAMAYOR',\n",
       " 'altonbrinja',\n",
       " '_WhyToby',\n",
       " 'Veelu2',\n",
       " 'waterslide',\n",
       " 'shaunmclane',\n",
       " 'kaylankors',\n",
       " 'HennesseyChad',\n",
       " 'SirChandlerBlog',\n",
       " 'tyler_digital',\n",
       " 'NW_Horadam',\n",
       " '_MrFreeze6',\n",
       " 'b_boogey_xl',\n",
       " '_sixFEEZY_',\n",
       " 'beauvans',\n",
       " 'cooliestillcool',\n",
       " 'MaraDavis',\n",
       " 'elyte4real',\n",
       " 'dramc2004',\n",
       " 'veasley80',\n",
       " '_Mr_Hooks',\n",
       " 'pinkprince93',\n",
       " '1moretennisnut',\n",
       " 'NickSears15',\n",
       " 'samzeb',\n",
       " 'TheMenzEffect',\n",
       " 'CiaraCummingsTV',\n",
       " 'kagibso',\n",
       " 'JohnTylerLynch',\n",
       " 'AnthonyMKreis',\n",
       " 'TaylorMDavis_',\n",
       " 'successwsagiven',\n",
       " 'efeyarbasi',\n",
       " 'JaakeNBaake',\n",
       " 'SheWantsTheVic',\n",
       " 'mrfunsiz3',\n",
       " 'jen_ch0i',\n",
       " 'kdhennny',\n",
       " 'ThugDebugger',\n",
       " 'RenderATL',\n",
       " 'AlisonWSB',\n",
       " 'MyOhMyaa_',\n",
       " 'kjaaddeee',\n",
       " 'SoleHeir',\n",
       " 'ErichinATL',\n",
       " 'mangle',\n",
       " 'ladykootoure',\n",
       " 'iAmPhiSho',\n",
       " 'mrsTayjay2015',\n",
       " 'BluedotGa',\n",
       " 'BrockWebsterXXX',\n",
       " 'hjlodge',\n",
       " 'jayacoop',\n",
       " 'NoahSCosi',\n",
       " 'DTF_yo_ma',\n",
       " 'JsoRad',\n",
       " 'corysparks',\n",
       " 'WhosJasmine',\n",
       " 'yonnalexis',\n",
       " 'marie_kailen',\n",
       " 'raquel_verde',\n",
       " 'YesSirJames',\n",
       " 'TheBee1775',\n",
       " 'dumbsillyguy',\n",
       " 'renee4atlanta',\n",
       " 'unbothered_x1',\n",
       " 'JanelForte',\n",
       " 'AtlantaAnna_',\n",
       " 'madisonbatts',\n",
       " 'TweetsByMojo',\n",
       " 'EWild',\n",
       " 'RareRonnie',\n",
       " 'dimanazzal',\n",
       " 'moldingmindz',\n",
       " 'darkskinnsheika',\n",
       " 'shesoobombb_',\n",
       " '_amariiiiiii',\n",
       " 'itsJalenB',\n",
       " 'YuriyATL',\n",
       " 'metro_man',\n",
       " 'branball',\n",
       " 'BenJMcFarland',\n",
       " 'leahwallabia',\n",
       " 'deeeche',\n",
       " 'on3ofone',\n",
       " 'kharmami',\n",
       " 'Bishop_Bizzle',\n",
       " 'rabbijosh',\n",
       " 'Ericperrytv',\n",
       " 'GeorgiaTech',\n",
       " 'darsmz',\n",
       " 'JustCallMeKoala',\n",
       " 'miguelangel_311',\n",
       " 'iyanilenicetv',\n",
       " 'jasonesteves',\n",
       " 'officiallyenny_',\n",
       " 'AmyBaugher',\n",
       " 'ShesTee_',\n",
       " '4ocious',\n",
       " 'fortforcongress',\n",
       " 'AlexIp718',\n",
       " 'SJP17',\n",
       " 'ohlizzi',\n",
       " 'byjad',\n",
       " 'joshuafkitchens',\n",
       " 'EloraRaymond',\n",
       " 'joknows98',\n",
       " 'andrewtclifton',\n",
       " 'TravonAnthony',\n",
       " 'danafowlefox5',\n",
       " 'WilliamMosher',\n",
       " 'flerlarlaloo',\n",
       " 'QueenLeets',\n",
       " 'UprEchelonCharm',\n",
       " 'MyanaSolomon',\n",
       " 'ShayRudeNRichie',\n",
       " 'OrdieflyApparel',\n",
       " 'mmeans40',\n",
       " 'BadassBbangem',\n",
       " 'LevinsReports',\n",
       " 'luxe64',\n",
       " 'thurzaa',\n",
       " 'MattATL21',\n",
       " 'mswarrior682',\n",
       " 'NikemaWilliams',\n",
       " 'MsJamie14',\n",
       " 'Jkitty__',\n",
       " 'heapevents',\n",
       " 'MsKushie404',\n",
       " 'amybarnes_usa',\n",
       " 'CarolinaPlug336',\n",
       " 'zoelmock',\n",
       " 'RossCollier',\n",
       " 'NiaMoTheFoXXX',\n",
       " 'techgirl1908',\n",
       " 'calenciaa',\n",
       " 'YoungMogul1_',\n",
       " 'uhltralord',\n",
       " 'ChrisRiceNY',\n",
       " 'Sgreyatl',\n",
       " 'terrinh73',\n",
       " 'terrilledward',\n",
       " 'theconnectsean',\n",
       " 'VSquirrel2',\n",
       " 'SEM_PBSA',\n",
       " 'beckyscheel',\n",
       " 'triciaharris',\n",
       " 'thetellbeall',\n",
       " 'whyamaya',\n",
       " '6ixretz',\n",
       " 'Ebonyize',\n",
       " 'myzdevyneone',\n",
       " 'Kitty404',\n",
       " 'SPWTalessia',\n",
       " 'jziglar',\n",
       " 'danhattan',\n",
       " 'WizMonifaaa',\n",
       " 'gudvibez',\n",
       " 'LinneaBaudhuin',\n",
       " 'cuteassotaku',\n",
       " 'darealkykilla',\n",
       " 'MelindaDav404',\n",
       " 'AyannaOfficial_',\n",
       " 'SCFLLATXGA',\n",
       " 'Dawn_Beth',\n",
       " 'NWildrews',\n",
       " 'susangbarber',\n",
       " 'K617L',\n",
       " 'ShelleyGarson',\n",
       " 'TherealSixman',\n",
       " 'Lionhearted_ben',\n",
       " 'buckheadcity4me',\n",
       " 'Ria_Martin',\n",
       " 'genarorivasPE',\n",
       " 'filmimpactga',\n",
       " 'ChrisTest82',\n",
       " 'viva_la_kamaura',\n",
       " 'CackalackiBoy',\n",
       " 'sydneyxchere',\n",
       " 'selfiegoddesss',\n",
       " 'OptimusGrind__',\n",
       " 'ItsJusNate',\n",
       " 'CindyBattles',\n",
       " 'mar_mar',\n",
       " 'TOOTASTYY',\n",
       " 'Djangotime4',\n",
       " 'keaijahawkins',\n",
       " '_slouise',\n",
       " 'QuincyAvery',\n",
       " 'DocWoc71',\n",
       " 'AdamPeshek',\n",
       " 'StateFarmArena',\n",
       " 'MarissaBHolt',\n",
       " 'SteveSchohan',\n",
       " 'javierabrown',\n",
       " 'StfuAndListenHo',\n",
       " '_heyimbrooke',\n",
       " 'tami__mcqueen',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sm_df['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b72f7fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(weekly_text['values'].tolist(), index=weekly_text['weekAuthored'])\n",
    "\n",
    "words_df = words_df.reset_index()\n",
    "words_df.to_pickle('keywords.pkl')\n",
    "\n",
    "words_df = pd.read_pickle('keywords.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
